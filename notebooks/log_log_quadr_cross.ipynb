{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from src.helpers import load_csv_data, standardize, remove_incomplete_columns, predict_labels, create_csv_submission, compute_accuracy\n",
    "from src.logistic.loss import compute_loss\n",
    "from src.logistic.not_req_impl import reg_logistic_regression\n",
    "from src.logistic.gradient import compute_gradient\n",
    "\n",
    "from src.helpers import remove_correlated_columns, get_jet_indexes, jet_indexes, log_indexes, get_all\n",
    "from src.polynomials import build_poly_matrix_quadratic\n",
    "from src.k_fold import build_k_indices\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "y, x_raw, ids = load_csv_data('../data/train.csv')\n",
    "init_col_n = x_raw.shape[1]\n",
    "init_col_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform y for logistic regression\n",
    "y[np.where(y == -1)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_jet_indexes = get_jet_indexes(x_raw)\n",
    "# x_jet_indexes = get_all(x_raw)\n",
    "x = x_raw\n",
    "# x_mass = np.zeros(x.shape[0])\n",
    "# x_mass[x[:, 0] == -999] = 1\n",
    "x[:, 0][x[:, 0] == -999] = np.median(x[:, 0][x[:, 0] != -999])\n",
    "# x = np.column_stack((x, x_mass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 2.5787159411771086\n",
      "Current iteration=1000, loss=[48723.13405209]\n",
      "||d|| = 5.922103991217265\n",
      "Current iteration=2000, loss=[49316.23811431]\n",
      "||d|| = 7.187825262124538\n",
      "Current iteration=3000, loss=[47112.09800444]\n",
      "||d|| = 1.2774213848064553\n",
      "Current iteration=4000, loss=[47590.02996856]\n",
      "||d|| = 3.5928271124780147\n",
      "Current iteration=5000, loss=[46988.97556607]\n",
      "||d|| = 16.16833323616141\n",
      "Current iteration=6000, loss=[46356.64971734]\n",
      "||d|| = 0.9629467944887913\n",
      "Current iteration=7000, loss=[46352.58603949]\n",
      "||d|| = 5.306026661594372\n",
      "Current iteration=8000, loss=[46224.20597002]\n",
      "||d|| = 3.808306576732271\n",
      "Current iteration=9000, loss=[46568.19341752]\n",
      "||d|| = 4.211216331407385\n",
      "loss=[46164.79383636]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 3.469929013599797\n",
      "Current iteration=1000, loss=[46925.37148927]\n",
      "||d|| = 7.224795563582372\n",
      "Current iteration=2000, loss=[47209.80848357]\n",
      "||d|| = 4.342158945304195\n",
      "Current iteration=3000, loss=[46341.56359176]\n",
      "||d|| = 15.456095701346426\n",
      "Current iteration=4000, loss=[47651.34008829]\n",
      "||d|| = 5.372523873349237\n",
      "Current iteration=5000, loss=[46258.85766943]\n",
      "||d|| = 1.8032377558289623\n",
      "Current iteration=6000, loss=[46427.70961522]\n",
      "||d|| = 24.159523778103228\n",
      "Current iteration=7000, loss=[46394.54055078]\n",
      "||d|| = 1.2924403319261182\n",
      "Current iteration=8000, loss=[46866.79935991]\n",
      "||d|| = 6.981705565186253\n",
      "Current iteration=9000, loss=[46658.227454]\n",
      "||d|| = 14.163770990615276\n",
      "loss=[46173.11263277]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 27.992528293731898\n",
      "Current iteration=1000, loss=[48906.91629198]\n",
      "||d|| = 21.508198768770644\n",
      "Current iteration=2000, loss=[47886.0536523]\n",
      "||d|| = 2.0969636136288194\n",
      "Current iteration=3000, loss=[47016.23159504]\n",
      "||d|| = 13.694161412386837\n",
      "Current iteration=4000, loss=[47515.38623812]\n",
      "||d|| = 4.339064511117669\n",
      "Current iteration=5000, loss=[46904.84406765]\n",
      "||d|| = 4.42646358539247\n",
      "Current iteration=6000, loss=[46602.05420809]\n",
      "||d|| = 56.51322883505971\n",
      "Current iteration=7000, loss=[46888.59897048]\n",
      "||d|| = 5.158088301112536\n",
      "Current iteration=8000, loss=[46526.50133113]\n",
      "||d|| = 6.964727961836589\n",
      "Current iteration=9000, loss=[47135.17038274]\n",
      "||d|| = 10.628987327974805\n",
      "loss=[46394.53142186]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 2.036458522693078\n",
      "Current iteration=1000, loss=[47870.82200113]\n",
      "||d|| = 4.841822759331324\n",
      "Current iteration=2000, loss=[47368.92938939]\n",
      "||d|| = 42.25187190432178\n",
      "Current iteration=3000, loss=[48200.84535455]\n",
      "||d|| = 1.7266054042214585\n",
      "Current iteration=4000, loss=[46730.81074322]\n",
      "||d|| = 31.40155439008291\n",
      "Current iteration=5000, loss=[46796.14171304]\n",
      "||d|| = 3.4706567525171828\n",
      "Current iteration=6000, loss=[49816.91840589]\n",
      "||d|| = 3.93509232299413\n",
      "Current iteration=7000, loss=[46532.54472856]\n",
      "||d|| = 5.017509220040997\n",
      "Current iteration=8000, loss=[48425.84653437]\n",
      "||d|| = 1.3038533334300266\n",
      "Current iteration=9000, loss=[46262.51744359]\n",
      "||d|| = 3.1853625095899556\n",
      "loss=[47064.24895484]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 11.889904202333884\n",
      "Current iteration=1000, loss=[48494.33210178]\n",
      "||d|| = 26.585195200153237\n",
      "Current iteration=2000, loss=[46717.27675359]\n",
      "||d|| = 13.327760713795882\n",
      "Current iteration=3000, loss=[46499.72747727]\n",
      "||d|| = 6.7959017221985265\n",
      "Current iteration=4000, loss=[46962.59182494]\n",
      "||d|| = 1.2445696688349954\n",
      "Current iteration=5000, loss=[46366.92760999]\n",
      "||d|| = 5.48021085642297\n",
      "Current iteration=6000, loss=[46266.35449867]\n",
      "||d|| = 6.3134680675340356\n",
      "Current iteration=7000, loss=[46431.71608114]\n",
      "||d|| = 2.145349813828544\n",
      "Current iteration=8000, loss=[46549.46221941]\n",
      "||d|| = 2.7551930528369266\n",
      "Current iteration=9000, loss=[46265.3159627]\n",
      "||d|| = 4.748758852742881\n",
      "loss=[47233.8440488]\n",
      "lambda=0.000000, Training accuracy=0.745, Testing accuracy=0.744\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 3.121963526314799\n",
      "Current iteration=1000, loss=[41165.05611255]\n",
      "||d|| = 13.254878315873516\n",
      "Current iteration=2000, loss=[43507.64823672]\n",
      "||d|| = 3.1515936211012026\n",
      "Current iteration=3000, loss=[40655.42665713]\n",
      "||d|| = 7.631929194835587\n",
      "Current iteration=4000, loss=[40945.67543527]\n",
      "||d|| = 4.327054348076598\n",
      "Current iteration=5000, loss=[42780.44927355]\n",
      "||d|| = 3.9339101602798885\n",
      "Current iteration=6000, loss=[41335.651971]\n",
      "||d|| = 3.584501461726176\n",
      "Current iteration=7000, loss=[40348.22538344]\n",
      "||d|| = 6.405053635315871\n",
      "Current iteration=8000, loss=[43869.77956288]\n",
      "||d|| = 4.664883538577875\n",
      "Current iteration=9000, loss=[40418.19113137]\n",
      "||d|| = 43.613286629113304\n",
      "loss=[40376.16042165]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 4.377252468290054\n",
      "Current iteration=1000, loss=[45205.40845738]\n",
      "||d|| = 2.5265585155285324\n",
      "Current iteration=2000, loss=[40583.09412127]\n",
      "||d|| = 14.489193198447266\n",
      "Current iteration=3000, loss=[40446.20761806]\n",
      "||d|| = 9.456402931038864\n",
      "Current iteration=4000, loss=[40732.63680769]\n",
      "||d|| = 2.682408512857374\n",
      "Current iteration=5000, loss=[40798.15920238]\n",
      "||d|| = 32.902394396631564\n",
      "Current iteration=6000, loss=[40698.66675545]\n",
      "||d|| = 4.9660374349291025\n",
      "Current iteration=7000, loss=[41457.11794676]\n",
      "||d|| = 5.371812988215759\n",
      "Current iteration=8000, loss=[40476.79942003]\n",
      "||d|| = 5.444090151558866\n",
      "Current iteration=9000, loss=[40311.08313223]\n",
      "||d|| = 4.239243476688029\n",
      "loss=[40327.40610148]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 21.05297406410774\n",
      "Current iteration=1000, loss=[41157.31297263]\n",
      "||d|| = 9.747298094812285\n",
      "Current iteration=2000, loss=[40774.3206772]\n",
      "||d|| = 7.86914041235554\n",
      "Current iteration=3000, loss=[42950.81192293]\n",
      "||d|| = 7.591253643906173\n",
      "Current iteration=4000, loss=[40678.78379189]\n",
      "||d|| = 2.2628169703876058\n",
      "Current iteration=5000, loss=[40942.69120528]\n",
      "||d|| = 3.313862537074612\n",
      "Current iteration=6000, loss=[40439.90950289]\n",
      "||d|| = 11.410834918563392\n",
      "Current iteration=7000, loss=[41388.718373]\n",
      "||d|| = 14.547081502031268\n",
      "Current iteration=8000, loss=[40463.4175937]\n",
      "||d|| = 4.966653167641798\n",
      "Current iteration=9000, loss=[40627.53357158]\n",
      "||d|| = 1.2012980179367427\n",
      "loss=[40347.03349475]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 14.422935680267145\n",
      "Current iteration=1000, loss=[40665.22489013]\n",
      "||d|| = 7.1123154972318\n",
      "Current iteration=2000, loss=[42513.70807759]\n",
      "||d|| = 10.245173799622528\n",
      "Current iteration=3000, loss=[41297.01214919]\n",
      "||d|| = 10.396445090772966\n",
      "Current iteration=4000, loss=[40368.75828455]\n",
      "||d|| = 2.407990044430058\n",
      "Current iteration=5000, loss=[40410.53731114]\n",
      "||d|| = 5.389088447689139\n",
      "Current iteration=6000, loss=[47267.06963987]\n",
      "||d|| = 4.034911317518237\n",
      "Current iteration=7000, loss=[41125.24606365]\n",
      "||d|| = 8.225225478162622\n",
      "Current iteration=8000, loss=[41235.08230324]\n",
      "||d|| = 3.341000643572774\n",
      "Current iteration=9000, loss=[40643.73064182]\n",
      "||d|| = 6.969487291920795\n",
      "loss=[40520.07883864]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 10.319166066009084\n",
      "Current iteration=1000, loss=[40946.59989402]\n",
      "||d|| = 3.6128644911816465\n",
      "Current iteration=2000, loss=[42810.756847]\n",
      "||d|| = 1.9522876427565075\n",
      "Current iteration=3000, loss=[40740.38417503]\n",
      "||d|| = 9.848233909711615\n",
      "Current iteration=4000, loss=[40406.01745399]\n",
      "||d|| = 34.67932305575409\n",
      "Current iteration=5000, loss=[40406.14364007]\n",
      "||d|| = 3.3787341750623208\n",
      "Current iteration=6000, loss=[42205.19522988]\n",
      "||d|| = 8.329767221882921\n",
      "Current iteration=7000, loss=[40320.73930144]\n",
      "||d|| = 6.407715915572022\n",
      "Current iteration=8000, loss=[40314.5914315]\n",
      "||d|| = 18.307027787804767\n",
      "Current iteration=9000, loss=[40531.91938829]\n",
      "||d|| = 8.09941853203313\n",
      "loss=[40441.57268376]\n",
      "lambda=0.000000, Training accuracy=0.642, Testing accuracy=0.645\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 12.089654858986156\n",
      "Current iteration=1000, loss=[45175.10646347]\n",
      "||d|| = 5.054438368054257\n",
      "Current iteration=2000, loss=[38635.776109]\n",
      "||d|| = 10.045383621535569\n",
      "Current iteration=3000, loss=[38439.35425602]\n",
      "||d|| = 12.12326608032745\n",
      "Current iteration=4000, loss=[38474.17089925]\n",
      "||d|| = 21.177882345285877\n",
      "Current iteration=5000, loss=[38769.6123826]\n",
      "||d|| = 5.265502834471641\n",
      "Current iteration=6000, loss=[38362.34701878]\n",
      "||d|| = 4.737471262202617\n",
      "Current iteration=7000, loss=[38375.5650865]\n",
      "||d|| = 6.648976912851143\n",
      "Current iteration=8000, loss=[38658.99899247]\n",
      "||d|| = 5.335963842827721\n",
      "Current iteration=9000, loss=[40336.21839731]\n",
      "||d|| = 6.746837616523258\n",
      "loss=[38363.3215185]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 7.829934147767218\n",
      "Current iteration=1000, loss=[39930.24279587]\n",
      "||d|| = 4.662717333624727\n",
      "Current iteration=2000, loss=[41014.44263467]\n",
      "||d|| = 6.956143968240886\n",
      "Current iteration=3000, loss=[38365.7855172]\n",
      "||d|| = 14.561558726525059\n",
      "Current iteration=4000, loss=[38337.01666243]\n",
      "||d|| = 17.81858576225167\n",
      "Current iteration=5000, loss=[38473.54859798]\n",
      "||d|| = 11.90665635410887\n",
      "Current iteration=6000, loss=[38248.30401199]\n",
      "||d|| = 7.6730087985536395\n",
      "Current iteration=7000, loss=[39590.53152205]\n",
      "||d|| = 14.246085143672865\n",
      "Current iteration=8000, loss=[38582.80803811]\n",
      "||d|| = 14.427261721887477\n",
      "Current iteration=9000, loss=[38849.88457083]\n",
      "||d|| = 11.884740841274956\n",
      "loss=[38353.62487554]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 4.505718668962651\n",
      "Current iteration=1000, loss=[39208.14294721]\n",
      "||d|| = 5.429189591278388\n",
      "Current iteration=2000, loss=[45260.19214242]\n",
      "||d|| = 10.421629699936135\n",
      "Current iteration=3000, loss=[38843.89468552]\n",
      "||d|| = 6.2481442273568835\n",
      "Current iteration=4000, loss=[39073.85464572]\n",
      "||d|| = 4.518079357655175\n",
      "Current iteration=5000, loss=[38443.3362025]\n",
      "||d|| = 5.02183581927184\n",
      "Current iteration=6000, loss=[38185.45025067]\n",
      "||d|| = 5.741448403133525\n",
      "Current iteration=7000, loss=[38926.05361073]\n",
      "||d|| = 21.112672787818045\n",
      "Current iteration=8000, loss=[40545.04320361]\n",
      "||d|| = 3.45674945631444\n",
      "Current iteration=9000, loss=[38899.05687345]\n",
      "||d|| = 4.877813477263171\n",
      "loss=[38169.54584987]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 26.961745092608062\n",
      "Current iteration=1000, loss=[38784.39810299]\n",
      "||d|| = 60.25223452171123\n",
      "Current iteration=2000, loss=[40973.55928362]\n",
      "||d|| = 9.788614895481873\n",
      "Current iteration=3000, loss=[39475.34700916]\n",
      "||d|| = 6.987938786886605\n",
      "Current iteration=4000, loss=[41447.75968068]\n",
      "||d|| = 5.777349381986947\n",
      "Current iteration=5000, loss=[38172.60038659]\n",
      "||d|| = 7.791404910074382\n",
      "Current iteration=6000, loss=[38239.6401395]\n",
      "||d|| = 5.390761606564263\n",
      "Current iteration=7000, loss=[38285.13018806]\n",
      "||d|| = 9.989184347474655\n",
      "Current iteration=8000, loss=[43716.53249506]\n",
      "||d|| = 2.305996177051096\n",
      "Current iteration=9000, loss=[38197.10599047]\n",
      "||d|| = 12.320651194990935\n",
      "loss=[38257.01616809]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 15.10551543420244\n",
      "Current iteration=1000, loss=[39298.97431713]\n",
      "||d|| = 28.037465698371616\n",
      "Current iteration=2000, loss=[39049.51417229]\n",
      "||d|| = 5.538630886987204\n",
      "Current iteration=3000, loss=[38808.06731305]\n",
      "||d|| = 10.009947076655594\n",
      "Current iteration=4000, loss=[38404.28777121]\n",
      "||d|| = 6.337185410144358\n",
      "Current iteration=5000, loss=[38421.59469711]\n",
      "||d|| = 5.314272030858169\n",
      "Current iteration=6000, loss=[38211.90500647]\n",
      "||d|| = 8.716718706409322\n",
      "Current iteration=7000, loss=[39158.29607108]\n",
      "||d|| = 6.033133542404114\n",
      "Current iteration=8000, loss=[38202.29395665]\n",
      "||d|| = 2.924860473281003\n",
      "Current iteration=9000, loss=[38231.05919317]\n",
      "||d|| = 6.772717334554552\n",
      "loss=[38356.65493099]\n",
      "lambda=0.000000, Training accuracy=0.577, Testing accuracy=0.573\n"
     ]
    }
   ],
   "source": [
    "ws, te_accs, tr_accs, te_losses, tr_losses = [], [], [], [], []\n",
    "lambda_ = 0\n",
    "k = 5\n",
    "\n",
    "for i in x_jet_indexes:\n",
    "    \n",
    "    y_i = y[x_jet_indexes[i]]\n",
    "    tx_i = x[x_jet_indexes[i]]\n",
    "    tx_del = np.delete(tx_i, jet_indexes[i], axis=1)\n",
    "    \n",
    "    for li in log_indexes:\n",
    "       # print(tx_del[:,li].min())\n",
    "       tx_del[:,li] = np.apply_along_axis(lambda n: np.log(1 + abs(tx_del[:,li].min()) + n), 0, tx_del[:,li])\n",
    "    \n",
    "    tx_std = standardize(tx_del)[0]\n",
    "    tx_poly = build_poly_matrix_quadratic(tx_std)\n",
    "    tx = np.c_[np.ones((y_i.shape[0], 1)), tx_poly]\n",
    "    \n",
    "    initial_w = np.zeros((tx.shape[1], 1))\n",
    "\n",
    "    k_indices = build_k_indices(y_i, k, 1)\n",
    "    \n",
    "    te_accs_k, tr_accs_k, te_losses_k, tr_losses_k, ws_k = [], [], [], [], []\n",
    "    \n",
    "    for k_ in range(k):\n",
    "        \n",
    "        test_indices = k_indices[k_]\n",
    "        train_indices = np.setdiff1d(k_indices.flatten(), test_indices)\n",
    "\n",
    "        y_train = y_i[train_indices]\n",
    "        x_train = tx[train_indices]\n",
    "        y_test = y_i[test_indices]\n",
    "        x_test = tx[test_indices]\n",
    "\n",
    "        # Ridge linear\n",
    "        w, loss_tr_k = reg_logistic_regression(y_train, x_train, initial_w, lambda_, 10000, 0.01, method='sgd', ratio=0.5)\n",
    "\n",
    "        # Calculate the loss for test data\n",
    "        loss_te_k = compute_loss(y_test, x_test, w)\n",
    "        \n",
    "        acc_tr_k = compute_accuracy(x_train, w, y_train, mode='logistic')\n",
    "        acc_te_k = compute_accuracy(x_test, w, y_test, mode='logistic')\n",
    "        \n",
    "        te_accs_k.append(acc_te_k)\n",
    "        tr_accs_k.append(acc_tr_k)\n",
    "        te_losses_k.append(np.math.sqrt(2 * loss_te_k))\n",
    "        tr_losses_k.append(np.math.sqrt(2 * loss_tr_k))\n",
    "\n",
    "        ws_k.append(w)\n",
    "        \n",
    "\n",
    "    te_accs.append(np.mean(te_accs_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    tr_accs.append(np.mean(acc_te_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    te_losses.append(np.mean(te_losses_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    tr_losses.append(np.mean(tr_losses_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    ws.append(np.mean(ws_k, axis=0))\n",
    "\n",
    "    print(\"lambda={l:.6f}, Training accuracy={tr:.3f}, Testing accuracy={te:.3f}\".format(\n",
    "           l=lambda_, tr=tr_accs[i] / y_i.shape[0], te=te_accs[i] / y_i.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "y, x_raw, ids = load_csv_data('../data/train.csv')\n",
    "init_col_n = x_raw.shape[1]\n",
    "init_col_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform y for logistic regression\n",
    "y[np.where(y == -1)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_jet_indexes = get_jet_indexes(x_raw)\n",
    "# x_jet_indexes = get_all(x_raw)\n",
    "x = x_raw\n",
    "x_mass = np.zeros(x.shape[0])\n",
    "x_mass[x[:, 0] == -999] = 1\n",
    "x[:, 0][x[:, 0] == -999] = np.median(x[:, 0][x[:, 0] != -999])\n",
    "x = np.column_stack((x, x_mass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 3.4241362425983177\n",
      "Current iteration=1000, loss=[49820.68382129]\n",
      "||d|| = 12.675298374652264\n",
      "Current iteration=2000, loss=[47261.71399705]\n",
      "||d|| = 2.795636048590469\n",
      "Current iteration=3000, loss=[46613.63864134]\n",
      "||d|| = 7.766423477049506\n",
      "Current iteration=4000, loss=[47082.00467998]\n",
      "||d|| = 11.5013856680073\n",
      "Current iteration=5000, loss=[46583.53475557]\n",
      "||d|| = 14.287333971330819\n",
      "Current iteration=6000, loss=[46299.55575193]\n",
      "||d|| = 3.871322223252055\n",
      "Current iteration=7000, loss=[46312.30588604]\n",
      "||d|| = 1.5363500856181416\n",
      "Current iteration=8000, loss=[46412.66924231]\n",
      "||d|| = 1.2021993539628\n",
      "Current iteration=9000, loss=[46184.71128872]\n",
      "||d|| = 8.766659316064718\n",
      "loss=[46976.23589851]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 10.246944292417446\n",
      "Current iteration=1000, loss=[48318.82925819]\n",
      "||d|| = 8.505885622731759\n",
      "Current iteration=2000, loss=[47809.82206217]\n",
      "||d|| = 5.960986018032392\n",
      "Current iteration=3000, loss=[46996.7634807]\n",
      "||d|| = 2.990073873218402\n",
      "Current iteration=4000, loss=[47083.48757497]\n",
      "||d|| = 11.179307457803494\n",
      "Current iteration=5000, loss=[46449.52492867]\n",
      "||d|| = 3.3918332530518085\n",
      "Current iteration=6000, loss=[46559.35974143]\n",
      "||d|| = 3.5751730003551043\n",
      "Current iteration=7000, loss=[46286.60844266]\n",
      "||d|| = 21.433297141884076\n",
      "Current iteration=8000, loss=[47278.00722121]\n",
      "||d|| = 4.8534121338208545\n",
      "Current iteration=9000, loss=[46353.83360372]\n",
      "||d|| = 12.906202734459686\n",
      "loss=[46151.68320496]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 3.508892865271336\n",
      "Current iteration=1000, loss=[49688.30497392]\n",
      "||d|| = 3.833248853343473\n",
      "Current iteration=2000, loss=[47420.52584499]\n",
      "||d|| = 10.50344608178783\n",
      "Current iteration=3000, loss=[47589.50957841]\n",
      "||d|| = 34.166062657442936\n",
      "Current iteration=4000, loss=[47354.82710778]\n",
      "||d|| = 8.715188445033508\n",
      "Current iteration=5000, loss=[47180.51632774]\n",
      "||d|| = 2.614639034398196\n",
      "Current iteration=6000, loss=[47037.0717513]\n",
      "||d|| = 4.12373791293291\n",
      "Current iteration=7000, loss=[47027.51711958]\n",
      "||d|| = 18.83944128390408\n",
      "Current iteration=8000, loss=[46469.53002355]\n",
      "||d|| = 1.8489122599287755\n",
      "Current iteration=9000, loss=[46461.55003146]\n",
      "||d|| = 6.3118510268578465\n",
      "loss=[47136.09687407]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 11.856395946972075\n",
      "Current iteration=1000, loss=[51268.56601582]\n",
      "||d|| = 15.419395616744895\n",
      "Current iteration=2000, loss=[47189.33729919]\n",
      "||d|| = 6.027715063448476\n",
      "Current iteration=3000, loss=[47091.22875393]\n",
      "||d|| = 8.681207416434743\n",
      "Current iteration=4000, loss=[46530.36588459]\n",
      "||d|| = 15.32395649705091\n",
      "Current iteration=5000, loss=[51367.08004608]\n",
      "||d|| = 1.9721857766600466\n",
      "Current iteration=6000, loss=[47822.14828045]\n",
      "||d|| = 4.377294334197134\n",
      "Current iteration=7000, loss=[46872.82747879]\n",
      "||d|| = 2.443873618663275\n",
      "Current iteration=8000, loss=[46357.7955906]\n",
      "||d|| = 2.883776917020428\n",
      "Current iteration=9000, loss=[46228.7878853]\n",
      "||d|| = 11.720419580021911\n",
      "loss=[46345.44468943]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 9.687859511735061\n",
      "Current iteration=1000, loss=[47790.46450241]\n",
      "||d|| = 5.04091541245699\n",
      "Current iteration=2000, loss=[46814.32255547]\n",
      "||d|| = 8.787725404470136\n",
      "Current iteration=3000, loss=[46759.8352866]\n",
      "||d|| = 3.5434792824255634\n",
      "Current iteration=4000, loss=[47410.88960821]\n",
      "||d|| = 9.324238376246823\n",
      "Current iteration=5000, loss=[48163.95880096]\n",
      "||d|| = 43.16481822034942\n",
      "Current iteration=6000, loss=[46861.34969092]\n",
      "||d|| = 81.87542038674901\n",
      "Current iteration=7000, loss=[46569.66626498]\n",
      "||d|| = 7.939746420775442\n",
      "Current iteration=8000, loss=[46355.2271993]\n",
      "||d|| = 1.5179006730112727\n",
      "Current iteration=9000, loss=[46277.98379521]\n",
      "||d|| = 1.5137232341831794\n",
      "loss=[46334.58519708]\n",
      "lambda=0.000000, Training accuracy=0.744, Testing accuracy=0.744\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 8.55587749328718\n",
      "Current iteration=1000, loss=[40737.45321881]\n",
      "||d|| = 4.76772247031763\n",
      "Current iteration=2000, loss=[41997.43025669]\n",
      "||d|| = 3.8561032310487513\n",
      "Current iteration=3000, loss=[45989.38767877]\n",
      "||d|| = 6.871095545621004\n",
      "Current iteration=4000, loss=[41141.14600627]\n",
      "||d|| = 2.8920578649255253\n",
      "Current iteration=5000, loss=[41988.73649895]\n",
      "||d|| = 8.852006230536928\n",
      "Current iteration=6000, loss=[40385.86593184]\n",
      "||d|| = 2.490595076731974\n",
      "Current iteration=7000, loss=[41117.03558001]\n",
      "||d|| = 3.7242400408061322\n",
      "Current iteration=8000, loss=[41112.98259175]\n",
      "||d|| = 39.32622474684313\n",
      "Current iteration=9000, loss=[40667.75747458]\n",
      "||d|| = 3.7363797635711777\n",
      "loss=[40706.25606118]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 14.014932766377\n",
      "Current iteration=1000, loss=[41265.1188368]\n",
      "||d|| = 4.511546819227367\n",
      "Current iteration=2000, loss=[40888.66578311]\n",
      "||d|| = 6.929676587220022\n",
      "Current iteration=3000, loss=[40652.49708639]\n",
      "||d|| = 87.04300858791001\n",
      "Current iteration=4000, loss=[40765.25572008]\n",
      "||d|| = 28.78034333464464\n",
      "Current iteration=5000, loss=[40416.45165588]\n",
      "||d|| = 4.841843535301959\n",
      "Current iteration=6000, loss=[40439.90357669]\n",
      "||d|| = 4.3766166104617295\n",
      "Current iteration=7000, loss=[40807.8185408]\n",
      "||d|| = 9.246255194999364\n",
      "Current iteration=8000, loss=[42354.59366317]\n",
      "||d|| = 12.610797175220876\n",
      "Current iteration=9000, loss=[42659.59973432]\n",
      "||d|| = 4.0860843603835395\n",
      "loss=[40418.55931378]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 19.2187904392528\n",
      "Current iteration=1000, loss=[42508.80034794]\n",
      "||d|| = 4.831480556793572\n",
      "Current iteration=2000, loss=[43150.56737098]\n",
      "||d|| = 7.086311199248344\n",
      "Current iteration=3000, loss=[42080.61534896]\n",
      "||d|| = 9.344597629745198\n",
      "Current iteration=4000, loss=[40822.41289216]\n",
      "||d|| = 6.6432705254076\n",
      "Current iteration=5000, loss=[40585.01282369]\n",
      "||d|| = 32.79962335841364\n",
      "Current iteration=6000, loss=[41025.12348221]\n",
      "||d|| = 17.255726058974044\n",
      "Current iteration=7000, loss=[40440.13544058]\n",
      "||d|| = 12.207703769882166\n",
      "Current iteration=8000, loss=[40440.52202895]\n",
      "||d|| = 15.165524348267159\n",
      "Current iteration=9000, loss=[40537.99782451]\n",
      "||d|| = 15.99015182099926\n",
      "loss=[40384.02544833]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 3.696811737446659\n",
      "Current iteration=1000, loss=[42341.94505905]\n",
      "||d|| = 6.104933770013996\n",
      "Current iteration=2000, loss=[40458.58657215]\n",
      "||d|| = 3.751546480028294\n",
      "Current iteration=3000, loss=[42092.35530518]\n",
      "||d|| = 16.041352865237066\n",
      "Current iteration=4000, loss=[40664.87285754]\n",
      "||d|| = 8.091187470408084\n",
      "Current iteration=5000, loss=[41657.7573499]\n",
      "||d|| = 7.116085668101949\n",
      "Current iteration=6000, loss=[40355.25045894]\n",
      "||d|| = 8.31200744042113\n",
      "Current iteration=7000, loss=[40822.78277883]\n",
      "||d|| = 9.466121570381437\n",
      "Current iteration=8000, loss=[40386.30398706]\n",
      "||d|| = 5.082186611933307\n",
      "Current iteration=9000, loss=[41252.24728882]\n",
      "||d|| = 22.75991338402421\n",
      "loss=[40678.31846226]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 18.66898830466372\n",
      "Current iteration=1000, loss=[43573.43963704]\n",
      "||d|| = 13.43240940822775\n",
      "Current iteration=2000, loss=[43628.06245118]\n",
      "||d|| = 5.655377518404222\n",
      "Current iteration=3000, loss=[40480.30968814]\n",
      "||d|| = 8.767630133991036\n",
      "Current iteration=4000, loss=[40596.18682463]\n",
      "||d|| = 17.794780348627054\n",
      "Current iteration=5000, loss=[40478.03614706]\n",
      "||d|| = 8.580274941748176\n",
      "Current iteration=6000, loss=[40394.78935983]\n",
      "||d|| = 5.488662609312045\n",
      "Current iteration=7000, loss=[40545.65411073]\n",
      "||d|| = 7.421529262268812\n",
      "Current iteration=8000, loss=[40365.53054343]\n",
      "||d|| = 10.607162408275638\n",
      "Current iteration=9000, loss=[40530.22844944]\n",
      "||d|| = 6.521267295943077\n",
      "loss=[40341.76289409]\n",
      "lambda=0.000000, Training accuracy=0.642, Testing accuracy=0.646\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 20.753324856307533\n",
      "Current iteration=1000, loss=[40732.22566575]\n",
      "||d|| = 4.822888039568025\n",
      "Current iteration=2000, loss=[38869.03026407]\n",
      "||d|| = 5.180294661547168\n",
      "Current iteration=3000, loss=[38452.1704135]\n",
      "||d|| = 6.394207750256021\n",
      "Current iteration=4000, loss=[38461.15305767]\n",
      "||d|| = 4.937702494151039\n",
      "Current iteration=5000, loss=[39071.86064975]\n",
      "||d|| = 9.283028973843495\n",
      "Current iteration=6000, loss=[38752.61217496]\n",
      "||d|| = 5.953791131994445\n",
      "Current iteration=7000, loss=[38145.77391149]\n",
      "||d|| = 4.901778694666989\n",
      "Current iteration=8000, loss=[38488.80261794]\n",
      "||d|| = 3.477102325752085\n",
      "Current iteration=9000, loss=[38226.3171755]\n",
      "||d|| = 11.087577094840848\n",
      "loss=[38096.53054743]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 8.593999246350004\n",
      "Current iteration=1000, loss=[39671.77005474]\n",
      "||d|| = 4.601244223576725\n",
      "Current iteration=2000, loss=[39757.93702159]\n",
      "||d|| = 8.103302265747699\n",
      "Current iteration=3000, loss=[40283.32740778]\n",
      "||d|| = 3.1023959830644974\n",
      "Current iteration=4000, loss=[39479.65744118]\n",
      "||d|| = 7.8692857951085005\n",
      "Current iteration=5000, loss=[40152.82533255]\n",
      "||d|| = 5.174959205560793\n",
      "Current iteration=6000, loss=[39627.43306998]\n",
      "||d|| = 6.090307041066672\n",
      "Current iteration=7000, loss=[38440.01051941]\n",
      "||d|| = 4.983061371572049\n",
      "Current iteration=8000, loss=[38425.50459398]\n",
      "||d|| = 3.9315377531850455\n",
      "Current iteration=9000, loss=[38170.87310144]\n",
      "||d|| = 4.4525844494658084\n",
      "loss=[39802.05000216]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 18.222278929368922\n",
      "Current iteration=1000, loss=[41274.06628266]\n",
      "||d|| = 5.707889481538137\n",
      "Current iteration=2000, loss=[38467.93853361]\n",
      "||d|| = 5.238524616459153\n",
      "Current iteration=3000, loss=[38618.34186868]\n",
      "||d|| = 3.1926059971625858\n",
      "Current iteration=4000, loss=[38921.25469337]\n",
      "||d|| = 11.368420817966184\n",
      "Current iteration=5000, loss=[38168.49516434]\n",
      "||d|| = 4.495395799037589\n",
      "Current iteration=6000, loss=[38061.56671597]\n",
      "||d|| = 6.031002920039724\n",
      "Current iteration=7000, loss=[39545.66989138]\n",
      "||d|| = 7.825307052193355\n",
      "Current iteration=8000, loss=[39178.62738493]\n",
      "||d|| = 6.844919329488618\n",
      "Current iteration=9000, loss=[38146.22786046]\n",
      "||d|| = 4.194026274693493\n",
      "loss=[38525.6046931]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 4.7801284396252415\n",
      "Current iteration=1000, loss=[42648.9101584]\n",
      "||d|| = 5.534989394701833\n",
      "Current iteration=2000, loss=[42030.00109147]\n",
      "||d|| = 71.11775547476758\n",
      "Current iteration=3000, loss=[38394.21998672]\n",
      "||d|| = 5.812785260454684\n",
      "Current iteration=4000, loss=[38676.23007234]\n",
      "||d|| = 24.962479592938763\n",
      "Current iteration=5000, loss=[38201.16230415]\n",
      "||d|| = 11.72331759007349\n",
      "Current iteration=6000, loss=[39643.7555477]\n",
      "||d|| = 3.080397699758339\n",
      "Current iteration=7000, loss=[39049.95242726]\n",
      "||d|| = 3.209811129849938\n",
      "Current iteration=8000, loss=[40387.15953105]\n",
      "||d|| = 4.8262665973390675\n",
      "Current iteration=9000, loss=[37986.75080471]\n",
      "||d|| = 5.020672812040634\n",
      "loss=[42356.69056615]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 26.690701989622546\n",
      "Current iteration=1000, loss=[39972.75303692]\n",
      "||d|| = 7.841577846346793\n",
      "Current iteration=2000, loss=[38859.74938555]\n",
      "||d|| = 33.61800438440989\n",
      "Current iteration=3000, loss=[38807.12156851]\n",
      "||d|| = 9.321353920140428\n",
      "Current iteration=4000, loss=[39465.61181829]\n",
      "||d|| = 5.975968257042185\n",
      "Current iteration=5000, loss=[39876.09085754]\n",
      "||d|| = 101.64032580494279\n",
      "Current iteration=6000, loss=[38514.78597252]\n",
      "||d|| = 8.7687354780285\n",
      "Current iteration=7000, loss=[39098.50111142]\n",
      "||d|| = 22.881427573156493\n",
      "Current iteration=8000, loss=[38268.21318325]\n",
      "||d|| = 3.709336668825347\n",
      "Current iteration=9000, loss=[38267.72295875]\n",
      "||d|| = 8.587048788651677\n",
      "loss=[38830.80789095]\n",
      "lambda=0.000000, Training accuracy=0.557, Testing accuracy=0.575\n"
     ]
    }
   ],
   "source": [
    "ws, te_accs, tr_accs, te_losses, tr_losses = [], [], [], [], []\n",
    "lambda_ = 0\n",
    "k = 5\n",
    "\n",
    "for i in x_jet_indexes:\n",
    "    \n",
    "    y_i = y[x_jet_indexes[i]]\n",
    "    tx_i = x[x_jet_indexes[i]]\n",
    "    tx_del = np.delete(tx_i, jet_indexes[i], axis=1)\n",
    "    \n",
    "    for li in log_indexes:\n",
    "       # print(tx_del[:,li].min())\n",
    "       tx_del[:,li] = np.apply_along_axis(lambda n: np.log(1 + abs(tx_del[:,li].min()) + n), 0, tx_del[:,li])\n",
    "    \n",
    "    tx_std = standardize(tx_del)[0]\n",
    "    tx_poly = build_poly_matrix_quadratic(tx_std)\n",
    "    tx = np.c_[np.ones((y_i.shape[0], 1)), tx_poly]\n",
    "    \n",
    "    initial_w = np.zeros((tx.shape[1], 1))\n",
    "\n",
    "    k_indices = build_k_indices(y_i, k, 1)\n",
    "    \n",
    "    te_accs_k, tr_accs_k, te_losses_k, tr_losses_k, ws_k = [], [], [], [], []\n",
    "    \n",
    "    for k_ in range(k):\n",
    "        \n",
    "        test_indices = k_indices[k_]\n",
    "        train_indices = np.setdiff1d(k_indices.flatten(), test_indices)\n",
    "\n",
    "        y_train = y_i[train_indices]\n",
    "        x_train = tx[train_indices]\n",
    "        y_test = y_i[test_indices]\n",
    "        x_test = tx[test_indices]\n",
    "\n",
    "        # Ridge linear\n",
    "        w, loss_tr_k = reg_logistic_regression(y_train, x_train, initial_w, lambda_, 10000, 0.01, method='sgd', ratio=0.5)\n",
    "\n",
    "        # Calculate the loss for test data\n",
    "        loss_te_k = compute_loss(y_test, x_test, w)\n",
    "        \n",
    "        acc_tr_k = compute_accuracy(x_train, w, y_train, mode='logistic')\n",
    "        acc_te_k = compute_accuracy(x_test, w, y_test, mode='logistic')\n",
    "        \n",
    "        te_accs_k.append(acc_te_k)\n",
    "        tr_accs_k.append(acc_tr_k)\n",
    "        te_losses_k.append(np.math.sqrt(2 * loss_te_k))\n",
    "        tr_losses_k.append(np.math.sqrt(2 * loss_tr_k))\n",
    "\n",
    "        ws_k.append(w)\n",
    "        \n",
    "\n",
    "    te_accs.append(np.mean(te_accs_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    tr_accs.append(np.mean(acc_te_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    te_losses.append(np.mean(te_losses_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    tr_losses.append(np.mean(tr_losses_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    ws.append(np.mean(ws_k, axis=0))\n",
    "\n",
    "    print(\"lambda={l:.6f}, Training accuracy={tr:.3f}, Testing accuracy={te:.3f}\".format(\n",
    "           l=lambda_, tr=tr_accs[i] / y_i.shape[0], te=te_accs[i] / y_i.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "y, x_raw, ids = load_csv_data('../data/train.csv')\n",
    "init_col_n = x_raw.shape[1]\n",
    "init_col_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform y for logistic regression\n",
    "y[np.where(y == -1)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_jet_indexes = get_jet_indexes(x_raw)\n",
    "# x_jet_indexes = get_all(x_raw)\n",
    "x = x_raw\n",
    "x_mass = np.zeros(x.shape[0])\n",
    "x_mass[x[:, 0] == -999] = 1\n",
    "x[:, 0][x[:, 0] == -999] = np.median(x[:, 0][x[:, 0] != -999])\n",
    "x = np.column_stack((x, x_mass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 6.476739119738675\n",
      "Current iteration=1000, loss=[38069.98310069]\n",
      "||d|| = 10.417890193416616\n",
      "Current iteration=2000, loss=[38339.38567851]\n",
      "||d|| = 4.652161093775247\n",
      "Current iteration=3000, loss=[37393.65378116]\n",
      "||d|| = 2.4425804190750786\n",
      "Current iteration=4000, loss=[37099.2471176]\n",
      "||d|| = 1.818833262249398\n",
      "Current iteration=5000, loss=[36853.63971436]\n",
      "||d|| = 2.1610816054541933\n",
      "Current iteration=6000, loss=[36460.39148303]\n",
      "||d|| = 1.0174059679392067\n",
      "Current iteration=7000, loss=[36424.98055793]\n",
      "||d|| = 6.904450684956423\n",
      "Current iteration=8000, loss=[36196.6889689]\n",
      "||d|| = 2.1274999535267787\n",
      "Current iteration=9000, loss=[36449.78074782]\n",
      "||d|| = 1.6229486924072816\n",
      "loss=[36227.84596917]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 4.726917060209904\n",
      "Current iteration=1000, loss=[38463.39625739]\n",
      "||d|| = 1.961411138204492\n",
      "Current iteration=2000, loss=[38102.62244801]\n",
      "||d|| = 5.856510404057953\n",
      "Current iteration=3000, loss=[38376.45051467]\n",
      "||d|| = 1.4193332011935473\n",
      "Current iteration=4000, loss=[37297.55095472]\n",
      "||d|| = 2.2066084361739198\n",
      "Current iteration=5000, loss=[37465.86805897]\n",
      "||d|| = 4.385903207942973\n",
      "Current iteration=6000, loss=[36916.17474677]\n",
      "||d|| = 2.4486283727105835\n",
      "Current iteration=7000, loss=[36441.27143264]\n",
      "||d|| = 2.0384058462823487\n",
      "Current iteration=8000, loss=[36233.492884]\n",
      "||d|| = 8.785143894224435\n",
      "Current iteration=9000, loss=[36487.97853187]\n",
      "||d|| = 5.946310807778464\n",
      "loss=[36003.47749408]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 4.7979915432586795\n",
      "Current iteration=1000, loss=[38461.34624398]\n",
      "||d|| = 7.166285233021003\n",
      "Current iteration=2000, loss=[37782.79118509]\n",
      "||d|| = 9.747097018292806\n",
      "Current iteration=3000, loss=[37286.37362362]\n",
      "||d|| = 2.6580581977355626\n",
      "Current iteration=4000, loss=[37065.3049748]\n",
      "||d|| = 2.895783170562011\n",
      "Current iteration=5000, loss=[37779.22409144]\n",
      "||d|| = 0.38898909967596634\n",
      "Current iteration=6000, loss=[36764.32426434]\n",
      "||d|| = 1.5540574351072582\n",
      "Current iteration=7000, loss=[36854.30241457]\n",
      "||d|| = 2.0300135838550846\n",
      "Current iteration=8000, loss=[36666.87563504]\n",
      "||d|| = 1.115697143847165\n",
      "Current iteration=9000, loss=[36745.50738868]\n",
      "||d|| = 1.2598935633164785\n",
      "loss=[36410.67722582]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 4.471302881672084\n",
      "Current iteration=1000, loss=[39397.03711107]\n",
      "||d|| = 1.9113176492152768\n",
      "Current iteration=2000, loss=[38112.18054169]\n",
      "||d|| = 3.464767214929188\n",
      "Current iteration=3000, loss=[37692.91866252]\n",
      "||d|| = 18.33938633512527\n",
      "Current iteration=4000, loss=[37589.99496369]\n",
      "||d|| = 2.5810226053496392\n",
      "Current iteration=5000, loss=[36912.18515607]\n",
      "||d|| = 11.041233242695883\n",
      "Current iteration=6000, loss=[36740.84839798]\n",
      "||d|| = 6.9199294528195265\n",
      "Current iteration=7000, loss=[36764.97819922]\n",
      "||d|| = 0.7897478196998088\n",
      "Current iteration=8000, loss=[36465.31050061]\n",
      "||d|| = 2.8171798383231788\n",
      "Current iteration=9000, loss=[36479.97834485]\n",
      "||d|| = 1.3377188704415954\n",
      "loss=[36227.82656962]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 4.142688233130077\n",
      "Current iteration=1000, loss=[38694.19068947]\n",
      "||d|| = 16.03104866658064\n",
      "Current iteration=2000, loss=[37245.51871422]\n",
      "||d|| = 2.0540848759133477\n",
      "Current iteration=3000, loss=[37073.96783486]\n",
      "||d|| = 0.9554110853837753\n",
      "Current iteration=4000, loss=[36792.90599362]\n",
      "||d|| = 0.9703717445963906\n",
      "Current iteration=5000, loss=[36933.35871773]\n",
      "||d|| = 2.0528668929631957\n",
      "Current iteration=6000, loss=[36489.01935535]\n",
      "||d|| = 1.6658003144722788\n",
      "Current iteration=7000, loss=[36413.39697724]\n",
      "||d|| = 1.8102917784280952\n",
      "Current iteration=8000, loss=[36342.93804961]\n",
      "||d|| = 0.9818652880317035\n",
      "Current iteration=9000, loss=[36159.42547305]\n",
      "||d|| = 3.165295882176401\n",
      "loss=[36448.86538234]\n",
      "lambda=0.000000, Training accuracy=0.757, Testing accuracy=0.776\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 7.542419084720914\n",
      "Current iteration=1000, loss=[48395.82370354]\n",
      "||d|| = 6.000219591615584\n",
      "Current iteration=2000, loss=[36823.09766797]\n",
      "||d|| = 2.3096804289474715\n",
      "Current iteration=3000, loss=[36359.1186252]\n",
      "||d|| = 16.45340901492483\n",
      "Current iteration=4000, loss=[36311.59872849]\n",
      "||d|| = 6.930436275691372\n",
      "Current iteration=5000, loss=[37694.50878957]\n",
      "||d|| = 18.994683186030343\n",
      "Current iteration=6000, loss=[35716.64820744]\n",
      "||d|| = 9.996151470730563\n",
      "Current iteration=7000, loss=[36026.02340903]\n",
      "||d|| = 3.0429815480903386\n",
      "Current iteration=8000, loss=[36182.26214766]\n",
      "||d|| = 5.8020332051370005\n",
      "Current iteration=9000, loss=[35294.03991269]\n",
      "||d|| = 6.381098513723713\n",
      "loss=[35289.4711136]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 6.19032209682852\n",
      "Current iteration=1000, loss=[37139.6933562]\n",
      "||d|| = 6.3590523799488174\n",
      "Current iteration=2000, loss=[36681.19490109]\n",
      "||d|| = 2.689671391206824\n",
      "Current iteration=3000, loss=[36623.84257325]\n",
      "||d|| = 1.9574626211886637\n",
      "Current iteration=4000, loss=[36711.67786014]\n",
      "||d|| = 6.50385852416217\n",
      "Current iteration=5000, loss=[36382.64535948]\n",
      "||d|| = 6.49758882114681\n",
      "Current iteration=6000, loss=[35511.7774761]\n",
      "||d|| = 5.024631537959729\n",
      "Current iteration=7000, loss=[35559.28444882]\n",
      "||d|| = 6.6878048491503925\n",
      "Current iteration=8000, loss=[35465.01387248]\n",
      "||d|| = 4.7581304341064685\n",
      "Current iteration=9000, loss=[35655.03482186]\n",
      "||d|| = 2.781233461067332\n",
      "loss=[35369.03590772]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 38.73185725774576\n",
      "Current iteration=1000, loss=[37739.88291147]\n",
      "||d|| = 26.028961334876815\n",
      "Current iteration=2000, loss=[36935.40738378]\n",
      "||d|| = 5.255273634689861\n",
      "Current iteration=3000, loss=[36230.19989472]\n",
      "||d|| = 5.799674634966796\n",
      "Current iteration=4000, loss=[36252.63978571]\n",
      "||d|| = 12.080786089999439\n",
      "Current iteration=5000, loss=[35921.28022176]\n",
      "||d|| = 1.929783188480257\n",
      "Current iteration=6000, loss=[35883.95395004]\n",
      "||d|| = 3.4875147555790673\n",
      "Current iteration=7000, loss=[35547.93040408]\n",
      "||d|| = 10.056180360011476\n",
      "Current iteration=8000, loss=[35646.15355226]\n",
      "||d|| = 5.838072621207293\n",
      "Current iteration=9000, loss=[37930.29551819]\n",
      "||d|| = 2.3794510336307257\n",
      "loss=[35344.38795798]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 5.422234482836186\n",
      "Current iteration=1000, loss=[40089.30623478]\n",
      "||d|| = 8.462638223729975\n",
      "Current iteration=2000, loss=[36896.30832801]\n",
      "||d|| = 5.237829463839263\n",
      "Current iteration=3000, loss=[36486.24058352]\n",
      "||d|| = 4.488092439897901\n",
      "Current iteration=4000, loss=[36958.36659891]\n",
      "||d|| = 6.362099942646932\n",
      "Current iteration=5000, loss=[35955.82328649]\n",
      "||d|| = 6.874969544565821\n",
      "Current iteration=6000, loss=[36279.31524986]\n",
      "||d|| = 2.9414496187843646\n",
      "Current iteration=7000, loss=[36674.36300738]\n",
      "||d|| = 5.3568987865102535\n",
      "Current iteration=8000, loss=[35767.37066192]\n",
      "||d|| = 2.9729746321128436\n",
      "Current iteration=9000, loss=[35647.06436026]\n",
      "||d|| = 4.497003740253281\n",
      "loss=[35971.32744474]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 11.239862794812705\n",
      "Current iteration=1000, loss=[39911.85636629]\n",
      "||d|| = 66.178156884955\n",
      "Current iteration=2000, loss=[38090.22247284]\n",
      "||d|| = 12.711550797488337\n",
      "Current iteration=3000, loss=[36475.36325455]\n",
      "||d|| = 3.4828059761453427\n",
      "Current iteration=4000, loss=[36185.42474103]\n",
      "||d|| = 4.646799038781379\n",
      "Current iteration=5000, loss=[35919.29299513]\n",
      "||d|| = 2.6621372756612165\n",
      "Current iteration=6000, loss=[36080.30939034]\n",
      "||d|| = 1.9502270501589958\n",
      "Current iteration=7000, loss=[35651.16623735]\n",
      "||d|| = 7.8991772489454\n",
      "Current iteration=8000, loss=[35825.77617715]\n",
      "||d|| = 5.1402854758283905\n",
      "Current iteration=9000, loss=[35448.52037637]\n",
      "||d|| = 3.4633246093925445\n",
      "loss=[35269.57081364]\n",
      "lambda=0.000000, Training accuracy=0.670, Testing accuracy=0.666\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 5.342251175081957\n",
      "Current iteration=1000, loss=[37019.17219633]\n",
      "||d|| = 12.218694883213837\n",
      "Current iteration=2000, loss=[35394.91935582]\n",
      "||d|| = 6.945787392410734\n",
      "Current iteration=3000, loss=[34548.09125549]\n",
      "||d|| = 2.81455952157248\n",
      "Current iteration=4000, loss=[34581.2295347]\n",
      "||d|| = 2.7068638633806112\n",
      "Current iteration=5000, loss=[34971.5425527]\n",
      "||d|| = 2.9804290961952513\n",
      "Current iteration=6000, loss=[34591.71628734]\n",
      "||d|| = 3.1229079490089275\n",
      "Current iteration=7000, loss=[33802.50709917]\n",
      "||d|| = 3.876046485905579\n",
      "Current iteration=8000, loss=[33788.15194672]\n",
      "||d|| = 0.004885829432739559\n",
      "Current iteration=9000, loss=[33771.93576779]\n",
      "||d|| = 3.9465663290246367\n",
      "loss=[33536.05806025]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 17.019987040282423\n",
      "Current iteration=1000, loss=[36187.80323556]\n",
      "||d|| = 16.950600359444916\n",
      "Current iteration=2000, loss=[35804.08059322]\n",
      "||d|| = 4.130235724482431\n",
      "Current iteration=3000, loss=[34357.1086727]\n",
      "||d|| = 2.709349665929329\n",
      "Current iteration=4000, loss=[34554.99332111]\n",
      "||d|| = 8.535608667044498\n",
      "Current iteration=5000, loss=[34521.25248469]\n",
      "||d|| = 8.748176564937248\n",
      "Current iteration=6000, loss=[33791.54444131]\n",
      "||d|| = 7.670509869415616\n",
      "Current iteration=7000, loss=[33905.38169833]\n",
      "||d|| = 0.001375109254406772\n",
      "Current iteration=8000, loss=[34481.54735822]\n",
      "||d|| = 5.646064227304624\n",
      "Current iteration=9000, loss=[33524.80190742]\n",
      "||d|| = 2.165281772743361\n",
      "loss=[33427.63743238]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 3.421983523474694\n",
      "Current iteration=1000, loss=[34923.01223044]\n",
      "||d|| = 2.051444315299996\n",
      "Current iteration=2000, loss=[34549.35594626]\n",
      "||d|| = 3.067049795758812\n",
      "Current iteration=3000, loss=[34159.14722016]\n",
      "||d|| = 7.852977581040591\n",
      "Current iteration=4000, loss=[34189.63899587]\n",
      "||d|| = 6.524895745000641\n",
      "Current iteration=5000, loss=[33787.74664422]\n",
      "||d|| = 21.277091012570374\n",
      "Current iteration=6000, loss=[34286.83819021]\n",
      "||d|| = 2.3117279023628496\n",
      "Current iteration=7000, loss=[33788.74643289]\n",
      "||d|| = 2.2134410084656597\n",
      "Current iteration=8000, loss=[33479.83118747]\n",
      "||d|| = 1.9636552073973792\n",
      "Current iteration=9000, loss=[33907.54781579]\n",
      "||d|| = 2.071524735983647\n",
      "loss=[33435.69394088]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 164.414487447205\n",
      "Current iteration=1000, loss=[50832.14834455]\n",
      "||d|| = 3.536745844912266\n",
      "Current iteration=2000, loss=[44271.48208603]\n",
      "||d|| = 2.151921051979165\n",
      "Current iteration=3000, loss=[41666.8402813]\n",
      "||d|| = 5.547555813676561\n",
      "Current iteration=4000, loss=[39775.31399254]\n",
      "||d|| = 14.615516461633431\n",
      "Current iteration=5000, loss=[38574.54980078]\n",
      "||d|| = 2.765758525809251\n",
      "Current iteration=6000, loss=[36868.26417745]\n",
      "||d|| = 3.5371405077831426\n",
      "Current iteration=7000, loss=[36180.43483077]\n",
      "||d|| = 7.925764625393072\n",
      "Current iteration=8000, loss=[35743.525561]\n",
      "||d|| = 2.431218054860121e-13\n",
      "Current iteration=9000, loss=[35571.42103708]\n",
      "||d|| = 2.631313391335239\n",
      "loss=[35044.04228502]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 28.576955619331887\n",
      "Current iteration=1000, loss=[36749.32340486]\n",
      "||d|| = 4.098097424293736\n",
      "Current iteration=2000, loss=[35718.63629712]\n",
      "||d|| = 3.1987562147872435\n",
      "Current iteration=3000, loss=[34686.50047443]\n",
      "||d|| = 2.3350178221568934\n",
      "Current iteration=4000, loss=[34587.33342146]\n",
      "||d|| = 3.3479951395781833\n",
      "Current iteration=5000, loss=[34381.66478973]\n",
      "||d|| = 8.625410808159424\n",
      "Current iteration=6000, loss=[34102.14369965]\n",
      "||d|| = 3.035207923278929\n",
      "Current iteration=7000, loss=[34027.91243551]\n",
      "||d|| = 8.510813880233627\n",
      "Current iteration=8000, loss=[34451.63803074]\n",
      "||d|| = 1.816184107272984\n",
      "Current iteration=9000, loss=[34290.738912]\n",
      "||d|| = 25.56759095440978\n",
      "loss=[33663.08412985]\n",
      "lambda=0.000000, Training accuracy=0.667, Testing accuracy=0.664\n"
     ]
    }
   ],
   "source": [
    "ws, te_accs, tr_accs, te_losses, tr_losses = [], [], [], [], []\n",
    "lambda_ = 0\n",
    "k = 5\n",
    "\n",
    "for i in x_jet_indexes:\n",
    "    \n",
    "    y_i = y[x_jet_indexes[i]]\n",
    "    tx_i = x[x_jet_indexes[i]]\n",
    "    tx_del = np.delete(tx_i, jet_indexes[i], axis=1)\n",
    "    \n",
    "    # for li in log_indexes:\n",
    "    #   # print(tx_del[:,li].min())\n",
    "    #   tx_del[:,li] = np.apply_along_axis(lambda n: np.log(1 + abs(tx_del[:,li].min()) + n), 0, tx_del[:,li])\n",
    "    \n",
    "    tx_std = standardize(tx_del)[0]\n",
    "    tx_poly = build_poly_matrix_quadratic(tx_std)\n",
    "    tx = np.c_[np.ones((y_i.shape[0], 1)), tx_poly]\n",
    "    \n",
    "    initial_w = np.zeros((tx.shape[1], 1))\n",
    "\n",
    "    k_indices = build_k_indices(y_i, k, 1)\n",
    "    \n",
    "    te_accs_k, tr_accs_k, te_losses_k, tr_losses_k, ws_k = [], [], [], [], []\n",
    "    \n",
    "    for k_ in range(k):\n",
    "        \n",
    "        test_indices = k_indices[k_]\n",
    "        train_indices = np.setdiff1d(k_indices.flatten(), test_indices)\n",
    "\n",
    "        y_train = y_i[train_indices]\n",
    "        x_train = tx[train_indices]\n",
    "        y_test = y_i[test_indices]\n",
    "        x_test = tx[test_indices]\n",
    "\n",
    "        # Ridge linear\n",
    "        w, loss_tr_k = reg_logistic_regression(y_train, x_train, initial_w, lambda_, 10000, 0.01, method='sgd', ratio=0.5)\n",
    "\n",
    "        # Calculate the loss for test data\n",
    "        loss_te_k = compute_loss(y_test, x_test, w)\n",
    "        \n",
    "        acc_tr_k = compute_accuracy(x_train, w, y_train, mode='logistic')\n",
    "        acc_te_k = compute_accuracy(x_test, w, y_test, mode='logistic')\n",
    "        \n",
    "        te_accs_k.append(acc_te_k)\n",
    "        tr_accs_k.append(acc_tr_k)\n",
    "        te_losses_k.append(np.math.sqrt(2 * loss_te_k))\n",
    "        tr_losses_k.append(np.math.sqrt(2 * loss_tr_k))\n",
    "\n",
    "        ws_k.append(w)\n",
    "        \n",
    "\n",
    "    te_accs.append(np.mean(te_accs_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    tr_accs.append(np.mean(acc_te_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    te_losses.append(np.mean(te_losses_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    tr_losses.append(np.mean(tr_losses_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    ws.append(np.mean(ws_k, axis=0))\n",
    "\n",
    "    print(\"lambda={l:.6f}, Training accuracy={tr:.3f}, Testing accuracy={te:.3f}\".format(\n",
    "           l=lambda_, tr=tr_accs[i] / y_i.shape[0], te=te_accs[i] / y_i.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "y, x_raw, ids = load_csv_data('../data/train.csv')\n",
    "init_col_n = x_raw.shape[1]\n",
    "init_col_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform y for logistic regression\n",
    "y[np.where(y == -1)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_jet_indexes = get_jet_indexes(x_raw)\n",
    "# x_jet_indexes = get_all(x_raw)\n",
    "x = x_raw\n",
    "# x_mass = np.zeros(x.shape[0])\n",
    "# x_mass[x[:, 0] == -999] = 1\n",
    "x[:, 0][x[:, 0] == -999] = np.median(x[:, 0][x[:, 0] != -999])\n",
    "# x = np.column_stack((x, x_mass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 8.625644532854063\n",
      "Current iteration=1000, loss=[38411.42511902]\n",
      "||d|| = 8.294951655184045\n",
      "Current iteration=2000, loss=[37840.09690223]\n",
      "||d|| = 3.4985747752798755\n",
      "Current iteration=3000, loss=[37398.20672033]\n",
      "||d|| = 1.8017233146020377\n",
      "Current iteration=4000, loss=[37204.65339111]\n",
      "||d|| = 10.249003794965903\n",
      "Current iteration=5000, loss=[37765.08317311]\n",
      "||d|| = 1.9573549262185745\n",
      "Current iteration=6000, loss=[36765.68436233]\n",
      "||d|| = 6.052507492681298\n",
      "Current iteration=7000, loss=[36769.59367373]\n",
      "||d|| = 4.6978093253947995\n",
      "Current iteration=8000, loss=[36557.40860552]\n",
      "||d|| = 1.2476174996270983\n",
      "Current iteration=9000, loss=[36562.32876424]\n",
      "||d|| = 5.455720183403461\n",
      "loss=[36276.21585838]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 19.41304749530535\n",
      "Current iteration=1000, loss=[38749.29699402]\n",
      "||d|| = 2.0336516351783835\n",
      "Current iteration=2000, loss=[38340.02406117]\n",
      "||d|| = 4.891001359336784\n",
      "Current iteration=3000, loss=[37485.8866449]\n",
      "||d|| = 1.0368221506426667\n",
      "Current iteration=4000, loss=[37302.53318798]\n",
      "||d|| = 10.291803407933214\n",
      "Current iteration=5000, loss=[37614.99268208]\n",
      "||d|| = 6.077048381026317\n",
      "Current iteration=6000, loss=[36739.12734679]\n",
      "||d|| = 2.4355021304892683\n",
      "Current iteration=7000, loss=[36483.31149967]\n",
      "||d|| = 7.146976170098881\n",
      "Current iteration=8000, loss=[36335.0522525]\n",
      "||d|| = 2.9685707384057913\n",
      "Current iteration=9000, loss=[36373.03039415]\n",
      "||d|| = 3.221528474492072\n",
      "loss=[36140.32003619]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 8.60412544860066\n",
      "Current iteration=1000, loss=[124308.39211014]\n",
      "||d|| = 7.8202354937037395\n",
      "Current iteration=2000, loss=[47738.77536657]\n",
      "||d|| = 3.114031778496306\n",
      "Current iteration=3000, loss=[44776.31898389]\n",
      "||d|| = 3.7329329082967173\n",
      "Current iteration=4000, loss=[42092.95580132]\n",
      "||d|| = 1.1128175129733529\n",
      "Current iteration=5000, loss=[41676.35362252]\n",
      "||d|| = 23.095585059095683\n",
      "Current iteration=6000, loss=[40529.7208239]\n",
      "||d|| = 1.8982006174407537\n",
      "Current iteration=7000, loss=[39407.32826032]\n",
      "||d|| = 7.7870489802374125\n",
      "Current iteration=8000, loss=[39096.39958539]\n",
      "||d|| = 1.4591559144488289\n",
      "Current iteration=9000, loss=[38187.69628665]\n",
      "||d|| = 10.877871008723165\n",
      "loss=[37923.73221121]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 8.278898404566883\n",
      "Current iteration=1000, loss=[39447.81558862]\n",
      "||d|| = 3.2140692017448886\n",
      "Current iteration=2000, loss=[38370.00207113]\n",
      "||d|| = 6.555868288572574\n",
      "Current iteration=3000, loss=[38168.24462321]\n",
      "||d|| = 6.683189075855741\n",
      "Current iteration=4000, loss=[37796.15595619]\n",
      "||d|| = 2.409536895819867\n",
      "Current iteration=5000, loss=[37380.11634]\n",
      "||d|| = 2.322713471524038\n",
      "Current iteration=6000, loss=[37151.09095877]\n",
      "||d|| = 1.1516269581387644\n",
      "Current iteration=7000, loss=[37023.20275104]\n",
      "||d|| = 7.058210633855636\n",
      "Current iteration=8000, loss=[37479.97644822]\n",
      "||d|| = 2.7982572573163784\n",
      "Current iteration=9000, loss=[37176.30036626]\n",
      "||d|| = 2.711760869674533\n",
      "loss=[40165.18569074]\n",
      "Current iteration=0, loss=[55401.8678478]\n",
      "||d|| = 5.208935589491456\n",
      "Current iteration=1000, loss=[39451.9927334]\n",
      "||d|| = 2.6545356626128394\n",
      "Current iteration=2000, loss=[37806.34714715]\n",
      "||d|| = 1.2603471958868837\n",
      "Current iteration=3000, loss=[37268.84473189]\n",
      "||d|| = 11.615734427045966\n",
      "Current iteration=4000, loss=[37096.71992575]\n",
      "||d|| = 2.7096824081775517\n",
      "Current iteration=5000, loss=[36740.95176985]\n",
      "||d|| = 1.6769535144933825\n",
      "Current iteration=6000, loss=[36666.90207599]\n",
      "||d|| = 1.6346835256781973\n",
      "Current iteration=7000, loss=[36681.28188657]\n",
      "||d|| = 6.388060417653753\n",
      "Current iteration=8000, loss=[36668.62918884]\n",
      "||d|| = 1.8037678329209677\n",
      "Current iteration=9000, loss=[36325.97819142]\n",
      "||d|| = 1.8121647190619024\n",
      "loss=[37036.6790279]\n",
      "lambda=0.000000, Training accuracy=0.756, Testing accuracy=0.769\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 10.300157441644402\n",
      "Current iteration=1000, loss=[37215.77987]\n",
      "||d|| = 4.289941570128123\n",
      "Current iteration=2000, loss=[36401.03585697]\n",
      "||d|| = 2.517304909074249\n",
      "Current iteration=3000, loss=[36092.01596417]\n",
      "||d|| = 3.101193391252472\n",
      "Current iteration=4000, loss=[36830.9140226]\n",
      "||d|| = 7.715440454482474\n",
      "Current iteration=5000, loss=[37021.58695211]\n",
      "||d|| = 11.407624025205083\n",
      "Current iteration=6000, loss=[35541.55013507]\n",
      "||d|| = 5.444259928505196\n",
      "Current iteration=7000, loss=[36402.73379784]\n",
      "||d|| = 6.052474507825968\n",
      "Current iteration=8000, loss=[35882.71996896]\n",
      "||d|| = 6.349797826495333\n",
      "Current iteration=9000, loss=[35678.56863232]\n",
      "||d|| = 3.457273360617183\n",
      "loss=[35213.76070422]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 5.473214263829696\n",
      "Current iteration=1000, loss=[38167.32441228]\n",
      "||d|| = 10.991649921192453\n",
      "Current iteration=2000, loss=[37167.27854327]\n",
      "||d|| = 4.867995506827081\n",
      "Current iteration=3000, loss=[36308.25353076]\n",
      "||d|| = 2.9075683372718397\n",
      "Current iteration=4000, loss=[42621.81029906]\n",
      "||d|| = 3.227735537374452\n",
      "Current iteration=5000, loss=[36738.79986528]\n",
      "||d|| = 3.4688068495742295\n",
      "Current iteration=6000, loss=[35548.19576156]\n",
      "||d|| = 73.34354263977643\n",
      "Current iteration=7000, loss=[35755.88852453]\n",
      "||d|| = 2.8488321788614126\n",
      "Current iteration=8000, loss=[35693.8320624]\n",
      "||d|| = 4.6848016097339285\n",
      "Current iteration=9000, loss=[35805.72280714]\n",
      "||d|| = 8.860726820609656\n",
      "loss=[35646.20166326]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 4.375367298679311\n",
      "Current iteration=1000, loss=[37491.85311626]\n",
      "||d|| = 9.440218909088205\n",
      "Current iteration=2000, loss=[37338.97383324]\n",
      "||d|| = 2.384179174190181\n",
      "Current iteration=3000, loss=[36815.88368702]\n",
      "||d|| = 2.14871560615275\n",
      "Current iteration=4000, loss=[36421.2019143]\n",
      "||d|| = 4.905401622222086\n",
      "Current iteration=5000, loss=[36159.96754025]\n",
      "||d|| = 6.528945175771364\n",
      "Current iteration=6000, loss=[36251.75027338]\n",
      "||d|| = 7.803600605807253\n",
      "Current iteration=7000, loss=[35928.53207372]\n",
      "||d|| = 6.205502948970045\n",
      "Current iteration=8000, loss=[35454.42237518]\n",
      "||d|| = 2.370387606315075\n",
      "Current iteration=9000, loss=[35383.13707762]\n",
      "||d|| = 8.188450674327937\n",
      "loss=[35333.10702195]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 5.78665259264975\n",
      "Current iteration=1000, loss=[38284.59535239]\n",
      "||d|| = 2.358667740912438\n",
      "Current iteration=2000, loss=[36793.74677578]\n",
      "||d|| = 6.292588219656398\n",
      "Current iteration=3000, loss=[37461.85018573]\n",
      "||d|| = 11.181086400534092\n",
      "Current iteration=4000, loss=[36646.08738742]\n",
      "||d|| = 4.67461939052753\n",
      "Current iteration=5000, loss=[36175.32857416]\n",
      "||d|| = 2.708732419443636\n",
      "Current iteration=6000, loss=[36047.35494618]\n",
      "||d|| = 3.446470057095315\n",
      "Current iteration=7000, loss=[36862.37628933]\n",
      "||d|| = 13.387013871063138\n",
      "Current iteration=8000, loss=[36009.63182003]\n",
      "||d|| = 1.5465939523637353\n",
      "Current iteration=9000, loss=[35906.72704969]\n",
      "||d|| = 5.951407741500836\n",
      "loss=[35852.55258171]\n",
      "Current iteration=0, loss=[42997.30590449]\n",
      "||d|| = 4.850188536967966\n",
      "Current iteration=1000, loss=[38295.74620194]\n",
      "||d|| = 6.646489803141947\n",
      "Current iteration=2000, loss=[36513.62856036]\n",
      "||d|| = 6.822163187712928\n",
      "Current iteration=3000, loss=[36105.9604601]\n",
      "||d|| = 7.328753673801609\n",
      "Current iteration=4000, loss=[36481.94650023]\n",
      "||d|| = 7.757100872141144\n",
      "Current iteration=5000, loss=[35741.51709937]\n",
      "||d|| = 2.220448325876865\n",
      "Current iteration=6000, loss=[35709.82176571]\n",
      "||d|| = 6.648536464741916\n",
      "Current iteration=7000, loss=[35698.88913449]\n",
      "||d|| = 1.540577790538479\n",
      "Current iteration=8000, loss=[36720.28894248]\n",
      "||d|| = 9.417514658738415e-06\n",
      "Current iteration=9000, loss=[35244.71613803]\n",
      "||d|| = 12.101050640415615\n",
      "loss=[35602.58355404]\n",
      "lambda=0.000000, Training accuracy=0.665, Testing accuracy=0.669\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 7.697477838525671\n",
      "Current iteration=1000, loss=[35292.93557716]\n",
      "||d|| = 0.002346437211384327\n",
      "Current iteration=2000, loss=[34841.15435288]\n",
      "||d|| = 6.899626628064337\n",
      "Current iteration=3000, loss=[34568.94442206]\n",
      "||d|| = 2.761035223007865\n",
      "Current iteration=4000, loss=[35685.80831163]\n",
      "||d|| = 13.02100195398589\n",
      "Current iteration=5000, loss=[33799.28271933]\n",
      "||d|| = 9.521419636358816\n",
      "Current iteration=6000, loss=[33918.8382745]\n",
      "||d|| = 4.713121722836796\n",
      "Current iteration=7000, loss=[33802.22141733]\n",
      "||d|| = 24.319940947606167\n",
      "Current iteration=8000, loss=[34266.80171916]\n",
      "||d|| = 6.38465465779208\n",
      "Current iteration=9000, loss=[33625.41475926]\n",
      "||d|| = 7.28070303678797\n",
      "loss=[34168.74304155]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 2.3484649465415206\n",
      "Current iteration=1000, loss=[35428.44607368]\n",
      "||d|| = 6.873583030908697\n",
      "Current iteration=2000, loss=[35494.79850197]\n",
      "||d|| = 21.64558108619054\n",
      "Current iteration=3000, loss=[34892.01040838]\n",
      "||d|| = 1.9918984867534726\n",
      "Current iteration=4000, loss=[34375.88452236]\n",
      "||d|| = 10.857379272223822\n",
      "Current iteration=5000, loss=[34140.55741527]\n",
      "||d|| = 2.9965163463729736\n",
      "Current iteration=6000, loss=[33869.7429246]\n",
      "||d|| = 3.326857952414811\n",
      "Current iteration=7000, loss=[33737.77304396]\n",
      "||d|| = 5.411948745228142\n",
      "Current iteration=8000, loss=[33900.11155035]\n",
      "||d|| = 5.386472387862732\n",
      "Current iteration=9000, loss=[33643.59576681]\n",
      "||d|| = 2.5204053208638806\n",
      "loss=[33577.47997758]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 31.458664752130623\n",
      "Current iteration=1000, loss=[36398.19917624]\n",
      "||d|| = 0.4244904844558011\n",
      "Current iteration=2000, loss=[36651.67384313]\n",
      "||d|| = 3.8188662057634573\n",
      "Current iteration=3000, loss=[34676.23362208]\n",
      "||d|| = 11.631854626085225\n",
      "Current iteration=4000, loss=[34543.44308166]\n",
      "||d|| = 2.5406618624652\n",
      "Current iteration=5000, loss=[34185.28959859]\n",
      "||d|| = 3.3146555742637376\n",
      "Current iteration=6000, loss=[34627.45878319]\n",
      "||d|| = 4.418347832152279\n",
      "Current iteration=7000, loss=[33769.55499432]\n",
      "||d|| = 2.4623708994496165\n",
      "Current iteration=8000, loss=[34257.25291252]\n",
      "||d|| = 3.9165325119512393\n",
      "Current iteration=9000, loss=[33725.09242632]\n",
      "||d|| = 8.093091687344442\n",
      "loss=[34537.30858029]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 4.260991900516669\n",
      "Current iteration=1000, loss=[35262.49082982]\n",
      "||d|| = 3.987599443379084\n",
      "Current iteration=2000, loss=[34811.05143534]\n",
      "||d|| = 2.049642649227609\n",
      "Current iteration=3000, loss=[34976.28948778]\n",
      "||d|| = 1.7958370044263865\n",
      "Current iteration=4000, loss=[34162.976282]\n",
      "||d|| = 14.669879597401849\n",
      "Current iteration=5000, loss=[34300.49927453]\n",
      "||d|| = 4.804853520051711\n",
      "Current iteration=6000, loss=[34408.81513769]\n",
      "||d|| = 2.060941675552196\n",
      "Current iteration=7000, loss=[33777.43879087]\n",
      "||d|| = 5.952103692762321\n",
      "Current iteration=8000, loss=[33650.92466852]\n",
      "||d|| = 2.163948430177532\n",
      "Current iteration=9000, loss=[33628.72322614]\n",
      "||d|| = 3.3784950956735087\n",
      "loss=[33557.71888914]\n",
      "Current iteration=0, loss=[40224.71718225]\n",
      "||d|| = 6.090201644980312\n",
      "Current iteration=1000, loss=[39231.41740729]\n",
      "||d|| = 3.413066115256804\n",
      "Current iteration=2000, loss=[36326.09745501]\n",
      "||d|| = 5.15760520553566\n",
      "Current iteration=3000, loss=[35583.20614301]\n",
      "||d|| = 4.575667146387647\n",
      "Current iteration=4000, loss=[35021.87621805]\n",
      "||d|| = 5.974053920685932\n",
      "Current iteration=5000, loss=[35317.29951619]\n",
      "||d|| = 5.56931187527941\n",
      "Current iteration=6000, loss=[34465.72696735]\n",
      "||d|| = 19.327459688582525\n",
      "Current iteration=7000, loss=[34492.52954157]\n",
      "||d|| = 6.055699132425868\n",
      "Current iteration=8000, loss=[34157.47634231]\n",
      "||d|| = 2.111806364387459\n",
      "Current iteration=9000, loss=[34654.95158926]\n",
      "||d|| = 4.26988467885171\n",
      "loss=[33942.97958636]\n",
      "lambda=0.000000, Training accuracy=0.655, Testing accuracy=0.654\n"
     ]
    }
   ],
   "source": [
    "ws, te_accs, tr_accs, te_losses, tr_losses = [], [], [], [], []\n",
    "lambda_ = 0\n",
    "k = 5\n",
    "\n",
    "for i in x_jet_indexes:\n",
    "    \n",
    "    y_i = y[x_jet_indexes[i]]\n",
    "    tx_i = x[x_jet_indexes[i]]\n",
    "    tx_del = np.delete(tx_i, jet_indexes[i], axis=1)\n",
    "    \n",
    "    # for li in log_indexes:\n",
    "    #   # print(tx_del[:,li].min())\n",
    "    #   tx_del[:,li] = np.apply_along_axis(lambda n: np.log(1 + abs(tx_del[:,li].min()) + n), 0, tx_del[:,li])\n",
    "    \n",
    "    tx_std = standardize(tx_del)[0]\n",
    "    tx_poly = build_poly_matrix_quadratic(tx_std)\n",
    "    tx = np.c_[np.ones((y_i.shape[0], 1)), tx_poly]\n",
    "    \n",
    "    initial_w = np.zeros((tx.shape[1], 1))\n",
    "\n",
    "    k_indices = build_k_indices(y_i, k, 1)\n",
    "    \n",
    "    te_accs_k, tr_accs_k, te_losses_k, tr_losses_k, ws_k = [], [], [], [], []\n",
    "    \n",
    "    for k_ in range(k):\n",
    "        \n",
    "        test_indices = k_indices[k_]\n",
    "        train_indices = np.setdiff1d(k_indices.flatten(), test_indices)\n",
    "\n",
    "        y_train = y_i[train_indices]\n",
    "        x_train = tx[train_indices]\n",
    "        y_test = y_i[test_indices]\n",
    "        x_test = tx[test_indices]\n",
    "\n",
    "        # Ridge linear\n",
    "        w, loss_tr_k = reg_logistic_regression(y_train, x_train, initial_w, lambda_, 10000, 0.01, method='sgd', ratio=0.5)\n",
    "\n",
    "        # Calculate the loss for test data\n",
    "        loss_te_k = compute_loss(y_test, x_test, w)\n",
    "        \n",
    "        acc_tr_k = compute_accuracy(x_train, w, y_train, mode='logistic')\n",
    "        acc_te_k = compute_accuracy(x_test, w, y_test, mode='logistic')\n",
    "        \n",
    "        te_accs_k.append(acc_te_k)\n",
    "        tr_accs_k.append(acc_tr_k)\n",
    "        te_losses_k.append(np.math.sqrt(2 * loss_te_k))\n",
    "        tr_losses_k.append(np.math.sqrt(2 * loss_tr_k))\n",
    "\n",
    "        ws_k.append(w)\n",
    "        \n",
    "\n",
    "    te_accs.append(np.mean(te_accs_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    tr_accs.append(np.mean(acc_te_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    te_losses.append(np.mean(te_losses_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    tr_losses.append(np.mean(tr_losses_k) * x[x_jet_indexes[i]].shape[0])\n",
    "    ws.append(np.mean(ws_k, axis=0))\n",
    "\n",
    "    print(\"lambda={l:.6f}, Training accuracy={tr:.3f}, Testing accuracy={te:.3f}\".format(\n",
    "           l=lambda_, tr=tr_accs[i] / y_i.shape[0], te=te_accs[i] / y_i.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.665112"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_raw\n",
    "x[:, 0][x[:, 0] == -999] = np.median(x[:, 0][x[:, 0] != -999])\n",
    "y_pred = np.zeros(x.shape[0])\n",
    "\n",
    "for i, w in enumerate(ws):\n",
    "    \n",
    "    tx_i = x[x_jet_indexes[i]]\n",
    "    tx_del = np.delete(tx_i, jet_indexes[i], axis=1)\n",
    "    \n",
    "    for li in log_indexes:\n",
    "        # print(tx_del[:,li].min())\n",
    "        tx_del[:,li] = np.apply_along_axis(lambda n: np.log(1 + abs(tx_del[:,li].min()) + n), 0, tx_del[:,li])\n",
    "    \n",
    "    tx_std = standardize(tx_del)[0]\n",
    "    tx_poly = build_poly_matrix_quadratic(tx_std)\n",
    "    tx = np.c_[np.ones((y_pred[x_jet_indexes[i]].shape[0], 1)), tx_poly]\n",
    "    \n",
    "    y_pred[x_jet_indexes[i]] = predict_labels(ws[i].flatten(), tx, mode='logistic')\n",
    "    \n",
    "(y == y_pred.reshape(-1, 1)).sum() / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub, x_sub_raw, ids_sub = load_csv_data('../data/test.csv')\n",
    "x_sub = x_sub_raw\n",
    "x_sub[:, 0][x_sub[:, 0] == -999] = np.median(x_sub[:, 0][x_sub[:, 0] != -999])\n",
    "sub_jet_indexes = get_jet_indexes(x_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, w in enumerate(ws):\n",
    "    \n",
    "    tx_i_sub = x_sub[sub_jet_indexes[i]]\n",
    "    tx_sub_del = np.delete(tx_i_sub, jet_indexes[i], axis=1)\n",
    "    \n",
    "    for li in log_indexes:\n",
    "        # print(tx_del[:,li].min())\n",
    "        tx_sub_del[:,li] = np.apply_along_axis(lambda n: np.log(1 + abs(tx_sub_del[:,li].min()) + n), 0, tx_sub_del[:,li])\n",
    "    \n",
    "    tx_sub_std = standardize(tx_sub_del)[0]\n",
    "    tx_sub_poly = build_poly_matrix_quadratic(tx_sub_std)\n",
    "    tx_sub = np.c_[np.ones((y_sub[sub_jet_indexes[i]].shape[0], 1)), tx_sub_poly]\n",
    "    \n",
    "    y_sub[x_jet_indexes[i]] = predict_labels(ws[i].flatten, tx_sub, mode='logistic')\n",
    "    \n",
    "create_csv_submission(ids_sub, y_sub, '../submissions/10-26.19-57.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
