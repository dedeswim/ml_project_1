{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from src.helpers import load_csv_data, standardize, remove_incomplete_columns, predict_labels, create_csv_submission\n",
    "from src.logistic.implementations import logistic_regression\n",
    "from src.logistic.loss import compute_loss\n",
    "from src.logistic.not_req_impl import reg_logistic_regression, gradient_descent_step\n",
    "from src.logistic.gradient import compute_gradient\n",
    "from src.split import split_data\n",
    "\n",
    "from src.logistic.sigmoid import sigmoid\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "y, x_raw, ids = load_csv_data('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "x, kept_columns = remove_incomplete_columns(x_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True, False, False, False,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "       False, False,  True])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform y for logistic regression\n",
    "y[np.where(y == -1)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize x and add the 1s column\n",
    "x, mean_x, std_x = standardize(x)\n",
    "tx = np.c_[np.ones((y.shape[0], 1)), x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "tx_train, y_train, tx_test, y_test = split_data(tx, y, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2262984\n",
      "Current iteration=73300, loss=[136962.1559508]\n",
      "||d|| = 0.5941439287913605\n",
      "Current iteration=73400, loss=[137321.24478922]\n",
      "||d|| = 1.3720806001791432\n",
      "Current iteration=73500, loss=[136879.39428901]\n",
      "||d|| = 0.21088987013687352\n",
      "Current iteration=73600, loss=[138473.90002365]\n",
      "||d|| = 0.34067314234831886\n",
      "Current iteration=73700, loss=[136274.09138344]\n",
      "||d|| = 0.897425031512749\n",
      "Current iteration=73800, loss=[136676.012739]\n",
      "||d|| = 0.3395781969356725\n",
      "Current iteration=73900, loss=[135257.75571366]\n",
      "||d|| = 0.5371458495169106\n",
      "Current iteration=74000, loss=[135827.87017012]\n",
      "||d|| = 0.5281365873490873\n",
      "Current iteration=74100, loss=[136897.46244334]\n",
      "||d|| = 0.5885020672193488\n",
      "Current iteration=74200, loss=[135893.05574127]\n",
      "||d|| = 0.4155854003366906\n",
      "Current iteration=74300, loss=[136641.44592865]\n",
      "||d|| = 1.22564450074405\n",
      "Current iteration=74400, loss=[135783.66237767]\n",
      "||d|| = 2.093968465640055\n",
      "Current iteration=74500, loss=[136596.64678365]\n",
      "||d|| = 2.1149871532145914\n",
      "Current iteration=74600, loss=[136258.84588905]\n",
      "||d|| = 0.8096951897669722\n",
      "Current iteration=74700, loss=[136736.49082646]\n",
      "||d|| = 0.8213712307306945\n",
      "Current iteration=74800, loss=[138063.42616]\n",
      "||d|| = 0.2278657338058619\n",
      "Current iteration=74900, loss=[137040.1980216]\n",
      "||d|| = 0.21842975001555287\n",
      "Current iteration=75000, loss=[137647.667955]\n",
      "||d|| = 1.3575652855039115\n",
      "Current iteration=75100, loss=[135710.61048851]\n",
      "||d|| = 0.30615904421757895\n",
      "Current iteration=75200, loss=[135558.86205317]\n",
      "||d|| = 1.943717973689379\n",
      "Current iteration=75300, loss=[135506.13478126]\n",
      "||d|| = 2.445567161100437\n",
      "Current iteration=75400, loss=[135860.29510536]\n",
      "||d|| = 0.5645488414034272\n",
      "Current iteration=75500, loss=[135325.64521849]\n",
      "||d|| = 0.6540026774783357\n",
      "Current iteration=75600, loss=[137197.77557128]\n",
      "||d|| = 0.6445516128958383\n",
      "Current iteration=75700, loss=[138231.71102307]\n",
      "||d|| = 0.012083243824925422\n",
      "Current iteration=75800, loss=[135727.24465127]\n",
      "||d|| = 0.5317010178386117\n",
      "Current iteration=75900, loss=[136441.81906201]\n",
      "||d|| = 0.3482561574259675\n",
      "Current iteration=76000, loss=[136119.8080316]\n",
      "||d|| = 0.6083588056733749\n",
      "Current iteration=76100, loss=[136926.55247296]\n",
      "||d|| = 0.42302177181305106\n",
      "Current iteration=76200, loss=[136121.85802918]\n",
      "||d|| = 0.7172885338508076\n",
      "Current iteration=76300, loss=[140165.48476815]\n",
      "||d|| = 0.4372332871321385\n",
      "Current iteration=76400, loss=[136435.87068562]\n",
      "||d|| = 0.9965604333646012\n",
      "Current iteration=76500, loss=[136263.36372573]\n",
      "||d|| = 0.21372553423371346\n",
      "Current iteration=76600, loss=[138328.79015843]\n",
      "||d|| = 0.13667412237125365\n",
      "Current iteration=76700, loss=[138224.41569547]\n",
      "||d|| = 1.4552384874457702\n",
      "Current iteration=76800, loss=[138611.51907609]\n",
      "||d|| = 2.3601664938601434\n",
      "Current iteration=76900, loss=[136858.94821414]\n",
      "||d|| = 0.16096119470313144\n",
      "Current iteration=77000, loss=[137464.91719354]\n",
      "||d|| = 0.11743227404055834\n",
      "Current iteration=77100, loss=[139018.62880727]\n",
      "||d|| = 3.0333207710700894\n",
      "Current iteration=77200, loss=[137183.50570746]\n",
      "||d|| = 0.37860686063303234\n",
      "Current iteration=77300, loss=[137079.00207914]\n",
      "||d|| = 0.8223199399895709\n",
      "Current iteration=77400, loss=[135388.49182474]\n",
      "||d|| = 0.4568285749134572\n",
      "Current iteration=77500, loss=[138199.60593426]\n",
      "||d|| = 1.0456215923755237\n",
      "Current iteration=77600, loss=[136083.84855041]\n",
      "||d|| = 0.27680120229674865\n",
      "Current iteration=77700, loss=[140515.396451]\n",
      "||d|| = 2.227404116501854\n",
      "Current iteration=77800, loss=[135605.34028311]\n",
      "||d|| = 0.5666352344010532\n",
      "Current iteration=77900, loss=[136022.65017418]\n",
      "||d|| = 0.7590624714417321\n",
      "Current iteration=78000, loss=[135629.91669508]\n",
      "||d|| = 0.558183392939043\n",
      "Current iteration=78100, loss=[135876.55618355]\n",
      "||d|| = 0.7846813638824649\n",
      "Current iteration=78200, loss=[135386.08275021]\n",
      "||d|| = 0.4192032959487607\n",
      "Current iteration=78300, loss=[135599.19737364]\n",
      "||d|| = 0.36409313358164636\n",
      "Current iteration=78400, loss=[138459.4622301]\n",
      "||d|| = 0.503560833939841\n",
      "Current iteration=78500, loss=[138802.90333841]\n",
      "||d|| = 0.20763963529572158\n",
      "Current iteration=78600, loss=[137280.37166838]\n",
      "||d|| = 0.8316966780767842\n",
      "Current iteration=78700, loss=[137030.34166475]\n",
      "||d|| = 0.5608940810181343\n",
      "Current iteration=78800, loss=[137165.0790754]\n",
      "||d|| = 2.194633755515415\n",
      "Current iteration=78900, loss=[135930.81709237]\n",
      "||d|| = 0.7266558743130714\n",
      "Current iteration=79000, loss=[135348.37960201]\n",
      "||d|| = 1.478565566966212\n",
      "Current iteration=79100, loss=[135325.49346795]\n",
      "||d|| = 1.382746100686768\n",
      "Current iteration=79200, loss=[135690.47495297]\n",
      "||d|| = 0.595114442649145\n",
      "Current iteration=79300, loss=[135474.54852514]\n",
      "||d|| = 0.8594347206345317\n",
      "Current iteration=79400, loss=[135517.74723766]\n",
      "||d|| = 1.160050177943502\n",
      "Current iteration=79500, loss=[137388.72167416]\n",
      "||d|| = 1.9377815149268758\n",
      "Current iteration=79600, loss=[138167.92661945]\n",
      "||d|| = 4.320968673512439\n",
      "Current iteration=79700, loss=[136630.25105502]\n",
      "||d|| = 0.7122501215286166\n",
      "Current iteration=79800, loss=[135746.36637874]\n",
      "||d|| = 0.9446040219946982\n",
      "Current iteration=79900, loss=[138565.26158933]\n",
      "||d|| = 0.7668555699331261\n",
      "Current iteration=80000, loss=[135322.44072983]\n",
      "||d|| = 1.8065474982883278\n",
      "Current iteration=80100, loss=[135586.98055432]\n",
      "||d|| = 0.9600604138617109\n",
      "Current iteration=80200, loss=[137757.35632777]\n",
      "||d|| = 0.7565640571487003\n",
      "Current iteration=80300, loss=[136554.31468226]\n",
      "||d|| = 0.7918219450590238\n",
      "Current iteration=80400, loss=[135831.18572602]\n",
      "||d|| = 0.668342646195651\n",
      "Current iteration=80500, loss=[136924.56604436]\n",
      "||d|| = 0.7835311433065989\n",
      "Current iteration=80600, loss=[135624.30258271]\n",
      "||d|| = 0.5709179061846746\n",
      "Current iteration=80700, loss=[137381.4887258]\n",
      "||d|| = 1.5733080380066955\n",
      "Current iteration=80800, loss=[136695.27012067]\n",
      "||d|| = 0.738963981992958\n",
      "Current iteration=80900, loss=[138135.09515519]\n",
      "||d|| = 1.4216497170456814\n",
      "Current iteration=81000, loss=[136987.97734809]\n",
      "||d|| = 1.032014474495985\n",
      "Current iteration=81100, loss=[136817.55906942]\n",
      "||d|| = 1.514787742694094\n",
      "Current iteration=81200, loss=[139108.57144215]\n",
      "||d|| = 1.1932829152753766\n",
      "Current iteration=81300, loss=[137042.56108166]\n",
      "||d|| = 0.6774602162870101\n",
      "Current iteration=81400, loss=[141016.73776211]\n",
      "||d|| = 0.901497828809325\n",
      "Current iteration=81500, loss=[137848.5480855]\n",
      "||d|| = 0.5631915323602636\n",
      "Current iteration=81600, loss=[136102.12084586]\n",
      "||d|| = 0.8530139474753351\n",
      "Current iteration=81700, loss=[135991.7613623]\n",
      "||d|| = 0.762671903929233\n",
      "Current iteration=81800, loss=[141891.93915023]\n",
      "||d|| = 0.26714281535570367\n",
      "Current iteration=81900, loss=[136123.56195912]\n",
      "||d|| = 2.1722994214962097\n",
      "Current iteration=82000, loss=[137147.8659869]\n",
      "||d|| = 1.553957470764361\n",
      "Current iteration=82100, loss=[135939.89340467]\n",
      "||d|| = 0.8078795640367309\n",
      "Current iteration=82200, loss=[136619.43837408]\n",
      "||d|| = 1.6191994681166229\n",
      "Current iteration=82300, loss=[137953.36991115]\n",
      "||d|| = 1.708257839829505\n",
      "Current iteration=82400, loss=[135901.19637323]\n",
      "||d|| = 0.6711019688808191\n",
      "Current iteration=82500, loss=[136181.08466817]\n",
      "||d|| = 0.5445134034048231\n",
      "Current iteration=82600, loss=[136489.95760112]\n",
      "||d|| = 0.8891447003221056\n",
      "Current iteration=82700, loss=[136486.71530182]\n",
      "||d|| = 0.5819801914857133\n",
      "Current iteration=82800, loss=[137756.26515111]\n",
      "||d|| = 0.7168449610819977\n",
      "Current iteration=82900, loss=[136050.72729676]\n",
      "||d|| = 0.48845798445542393\n",
      "Current iteration=83000, loss=[135888.66478226]\n",
      "||d|| = 1.5618043548582774\n",
      "Current iteration=83100, loss=[136987.26628544]\n",
      "||d|| = 0.44575810031479324\n",
      "Current iteration=83200, loss=[136487.33136321]\n",
      "||d|| = 0.9058371113285273\n",
      "Current iteration=83300, loss=[145975.27686118]\n",
      "||d|| = 0.985795496757725\n",
      "Current iteration=83400, loss=[135642.44656744]\n",
      "||d|| = 0.7271016674480723\n",
      "Current iteration=83500, loss=[137753.81663614]\n",
      "||d|| = 0.6585128362670096\n",
      "Current iteration=83600, loss=[137280.55896394]\n",
      "||d|| = 1.7724284347657822\n",
      "Current iteration=83700, loss=[135381.5798417]\n",
      "||d|| = 0.26567448230915736\n",
      "Current iteration=83800, loss=[135511.23306983]\n",
      "||d|| = 0.6594024827369679\n",
      "Current iteration=83900, loss=[136597.04691229]\n",
      "||d|| = 1.5698580735953946\n",
      "Current iteration=84000, loss=[135402.99106222]\n",
      "||d|| = 0.4114875047042541\n",
      "Current iteration=84100, loss=[136169.09248219]\n",
      "||d|| = 1.0134516788997452\n",
      "Current iteration=84200, loss=[135368.28890862]\n",
      "||d|| = 0.6792565148272959\n",
      "Current iteration=84300, loss=[135976.6677374]\n",
      "||d|| = 0.49749202627184463\n",
      "Current iteration=84400, loss=[136388.37055352]\n",
      "||d|| = 0.5703272688444369\n",
      "Current iteration=84500, loss=[138033.57228926]\n",
      "||d|| = 0.8280458093810017\n",
      "Current iteration=84600, loss=[143091.54576824]\n",
      "||d|| = 0.9587804822467353\n",
      "Current iteration=84700, loss=[136242.81649109]\n",
      "||d|| = 2.4872526737888787\n",
      "Current iteration=84800, loss=[136326.73767511]\n",
      "||d|| = 1.7019054179531636\n",
      "Current iteration=84900, loss=[135612.32320111]\n",
      "||d|| = 2.484874328043018\n",
      "Current iteration=85000, loss=[135915.79817326]\n",
      "||d|| = 1.8458262753296304\n",
      "Current iteration=85100, loss=[135852.90009831]\n",
      "||d|| = 2.781380848731946\n",
      "Current iteration=85200, loss=[136072.22183125]\n",
      "||d|| = 0.7647750745711382\n",
      "Current iteration=85300, loss=[138913.81872394]\n",
      "||d|| = 2.72799735518996\n",
      "Current iteration=85400, loss=[135238.19315814]\n",
      "||d|| = 1.010378770195894\n",
      "Current iteration=85500, loss=[137829.64690962]\n",
      "||d|| = 0.7732941997199992\n",
      "Current iteration=85600, loss=[139043.74909957]\n",
      "||d|| = 0.5832617416906453\n",
      "Current iteration=85700, loss=[136251.94709118]\n",
      "||d|| = 0.3515536819322966\n",
      "Current iteration=85800, loss=[136893.3414065]\n",
      "||d|| = 8.210937806679544\n",
      "Current iteration=85900, loss=[135545.07809101]\n",
      "||d|| = 0.49459288474788227\n",
      "Current iteration=86000, loss=[135883.10482963]\n",
      "||d|| = 0.3689721894246625\n",
      "Current iteration=86100, loss=[135367.09190683]\n",
      "||d|| = 1.4039206338859398\n",
      "Current iteration=86200, loss=[135878.3795383]\n",
      "||d|| = 0.5239626391219737\n",
      "Current iteration=86300, loss=[135879.34236437]\n",
      "||d|| = 2.305034299571613\n",
      "Current iteration=86400, loss=[136634.01348748]\n",
      "||d|| = 2.062974527611207\n",
      "Current iteration=86500, loss=[136514.03632238]\n",
      "||d|| = 0.4568062818156287\n",
      "Current iteration=86600, loss=[136125.72975188]\n",
      "||d|| = 3.2565243625589892\n",
      "Current iteration=86700, loss=[135388.36301794]\n",
      "||d|| = 2.295902941726232\n",
      "Current iteration=86800, loss=[135452.73492512]\n",
      "||d|| = 0.7538741406477719\n",
      "Current iteration=86900, loss=[135452.28076288]\n",
      "||d|| = 0.5058779040318773\n",
      "Current iteration=87000, loss=[136504.76813101]\n",
      "||d|| = 0.45367959939166197\n",
      "Current iteration=87100, loss=[135890.06717403]\n",
      "||d|| = 0.2725773674929108\n",
      "Current iteration=87200, loss=[137097.84366951]\n",
      "||d|| = 0.6476524969777108\n",
      "Current iteration=87300, loss=[135685.83825204]\n",
      "||d|| = 1.1334568270122116\n",
      "Current iteration=87400, loss=[135959.12064052]\n",
      "||d|| = 0.3793838748341109\n",
      "Current iteration=87500, loss=[135897.42356261]\n",
      "||d|| = 1.4819397272827186\n",
      "Current iteration=87600, loss=[140495.4248323]\n",
      "||d|| = 1.4033741416996794\n",
      "Current iteration=87700, loss=[136052.90365081]\n",
      "||d|| = 2.375246869515438\n",
      "Current iteration=87800, loss=[135758.46643793]\n",
      "||d|| = 0.7259245801913019\n",
      "Current iteration=87900, loss=[135928.37028052]\n",
      "||d|| = 3.106289588725011\n",
      "Current iteration=88000, loss=[135973.53670923]\n",
      "||d|| = 0.5178693952273464\n",
      "Current iteration=88100, loss=[136722.22104877]\n",
      "||d|| = 1.2599604755721134\n",
      "Current iteration=88200, loss=[137016.14845075]\n",
      "||d|| = 9.025863783444619\n",
      "Current iteration=88300, loss=[141354.67380824]\n",
      "||d|| = 0.8532531687090217\n",
      "Current iteration=88400, loss=[135592.06179946]\n",
      "||d|| = 0.547005035459587\n",
      "Current iteration=88500, loss=[137336.86426319]\n",
      "||d|| = 9.132729233458427\n",
      "Current iteration=88600, loss=[136531.71393369]\n",
      "||d|| = 0.7379708571460744\n",
      "Current iteration=88700, loss=[136773.73584981]\n",
      "||d|| = 1.0826087863933622\n",
      "Current iteration=88800, loss=[136774.30482823]\n",
      "||d|| = 1.1216960498344188\n",
      "Current iteration=88900, loss=[135891.10654497]\n",
      "||d|| = 0.3566391199543118\n",
      "Current iteration=89000, loss=[135300.42657569]\n",
      "||d|| = 0.4752540021182206\n",
      "Current iteration=89100, loss=[135838.93243484]\n",
      "||d|| = 0.7668563116975473\n",
      "Current iteration=89200, loss=[138615.36615186]\n",
      "||d|| = 0.6020275237192694\n",
      "Current iteration=89300, loss=[135720.67149391]\n",
      "||d|| = 2.801332472873333\n",
      "Current iteration=89400, loss=[136113.55145776]\n",
      "||d|| = 1.0835750709972074\n",
      "Current iteration=89500, loss=[137320.72262695]\n",
      "||d|| = 1.9643478690259886\n",
      "Current iteration=89600, loss=[137847.43964142]\n",
      "||d|| = 0.10922238971917955\n",
      "Current iteration=89700, loss=[137532.26573446]\n",
      "||d|| = 0.27323289177613497\n",
      "Current iteration=89800, loss=[140793.96546135]\n",
      "||d|| = 0.49166761711440055\n",
      "Current iteration=89900, loss=[136878.4532025]\n",
      "||d|| = 0.5070532913159556\n",
      "Current iteration=90000, loss=[137573.07102101]\n",
      "||d|| = 0.24733849915656117\n",
      "Current iteration=90100, loss=[136461.94474493]\n",
      "||d|| = 1.5185950258668335\n",
      "Current iteration=90200, loss=[136313.86011641]\n",
      "||d|| = 2.0809733111021935\n",
      "Current iteration=90300, loss=[136150.26190789]\n",
      "||d|| = 1.95824983915048\n",
      "Current iteration=90400, loss=[137216.38258127]\n",
      "||d|| = 0.8219184200143094\n",
      "Current iteration=90500, loss=[137818.42946337]\n",
      "||d|| = 1.466383091974109\n",
      "Current iteration=90600, loss=[143063.23474744]\n",
      "||d|| = 1.786477037842128\n",
      "Current iteration=90700, loss=[135954.00193905]\n",
      "||d|| = 0.8723906525974962\n",
      "Current iteration=90800, loss=[135220.06548456]\n",
      "||d|| = 0.8332312913966156\n",
      "Current iteration=90900, loss=[135590.80948095]\n",
      "||d|| = 0.6666724972394255\n",
      "Current iteration=91000, loss=[136471.12651422]\n",
      "||d|| = 0.9779528615746541\n",
      "Current iteration=91100, loss=[136139.87655462]\n",
      "||d|| = 0.278202400268353\n",
      "Current iteration=91200, loss=[136576.70911024]\n",
      "||d|| = 1.6743626319567664\n",
      "Current iteration=91300, loss=[136047.39459987]\n",
      "||d|| = 0.8986778093403642\n",
      "Current iteration=91400, loss=[135342.15687763]\n",
      "||d|| = 0.31315485153065614\n",
      "Current iteration=91500, loss=[135846.00714128]\n",
      "||d|| = 2.3931719742069\n",
      "Current iteration=91600, loss=[137878.31276662]\n",
      "||d|| = 0.8522207412726946\n",
      "Current iteration=91700, loss=[136244.34569071]\n",
      "||d|| = 0.6308070019470555\n",
      "Current iteration=91800, loss=[135205.26047855]\n",
      "||d|| = 0.4075997616254629\n",
      "Current iteration=91900, loss=[137308.5277344]\n",
      "||d|| = 0.9034454255774695\n",
      "Current iteration=92000, loss=[135960.21480356]\n",
      "||d|| = 1.1038992384068662\n",
      "Current iteration=92100, loss=[135434.36942563]\n",
      "||d|| = 0.8735270860885093\n",
      "Current iteration=92200, loss=[138425.52065935]\n",
      "||d|| = 0.5454950966506854\n",
      "Current iteration=92300, loss=[138096.43205155]\n",
      "||d|| = 0.7434759224123049\n",
      "Current iteration=92400, loss=[135839.98131473]\n",
      "||d|| = 0.2615064914821458\n",
      "Current iteration=92500, loss=[135456.91570905]\n",
      "||d|| = 0.8521432911301143\n",
      "Current iteration=92600, loss=[138101.58662391]\n",
      "||d|| = 0.47644156260171555\n",
      "Current iteration=92700, loss=[138657.96891294]\n",
      "||d|| = 1.487397793898417\n",
      "Current iteration=92800, loss=[136079.54837289]\n",
      "||d|| = 0.26207258488115887\n",
      "Current iteration=92900, loss=[135387.46619488]\n",
      "||d|| = 1.3207767813353346\n",
      "Current iteration=93000, loss=[135392.27546728]\n",
      "||d|| = 0.4026690772261116\n",
      "Current iteration=93100, loss=[136230.0925157]\n",
      "||d|| = 0.874673950262353\n",
      "Current iteration=93200, loss=[135695.40869822]\n",
      "||d|| = 0.48879663863583134\n",
      "Current iteration=93300, loss=[135952.30854697]\n",
      "||d|| = 0.782870444727551\n",
      "Current iteration=93400, loss=[135959.6475269]\n",
      "||d|| = 3.798187675906667\n",
      "Current iteration=93500, loss=[138895.49187024]\n",
      "||d|| = 2.1982934534491045\n",
      "Current iteration=93600, loss=[136465.53530516]\n",
      "||d|| = 1.9686435977451318\n",
      "Current iteration=93700, loss=[139166.72026377]\n",
      "||d|| = 0.8307481768590355\n",
      "Current iteration=93800, loss=[135715.21134043]\n",
      "||d|| = 1.912731956818151\n",
      "Current iteration=93900, loss=[136726.12708343]\n",
      "||d|| = 2.4740954414081506\n",
      "Current iteration=94000, loss=[136000.58176325]\n",
      "||d|| = 0.43853481423944507\n",
      "Current iteration=94100, loss=[135575.9806298]\n",
      "||d|| = 0.7992972034647281\n",
      "Current iteration=94200, loss=[137018.81872156]\n",
      "||d|| = 0.6917426284996631\n",
      "Current iteration=94300, loss=[138416.40265402]\n",
      "||d|| = 0.4086325275939456\n",
      "Current iteration=94400, loss=[137418.31863686]\n",
      "||d|| = 0.6743997643219525\n",
      "Current iteration=94500, loss=[136299.74384336]\n",
      "||d|| = 1.528367547436564\n",
      "Current iteration=94600, loss=[135522.72795542]\n",
      "||d|| = 1.7221858221966695\n",
      "Current iteration=94700, loss=[138751.8248946]\n",
      "||d|| = 1.3097015459825294\n",
      "Current iteration=94800, loss=[135953.13104509]\n",
      "||d|| = 1.1145826212992234\n",
      "Current iteration=94900, loss=[135527.88333417]\n",
      "||d|| = 1.6448457271600259\n",
      "Current iteration=95000, loss=[135811.53389132]\n",
      "||d|| = 1.2179612278127352\n",
      "Current iteration=95100, loss=[136185.39875861]\n",
      "||d|| = 0.7492930390815098\n",
      "Current iteration=95200, loss=[136933.11762018]\n",
      "||d|| = 1.3157693917266005\n",
      "Current iteration=95300, loss=[136459.5023392]\n",
      "||d|| = 0.5109633797749752\n",
      "Current iteration=95400, loss=[136525.06677506]\n",
      "||d|| = 1.3754562999650022\n",
      "Current iteration=95500, loss=[138841.221715]\n",
      "||d|| = 1.4917640422196945\n",
      "Current iteration=95600, loss=[138791.11344752]\n",
      "||d|| = 0.34879478609558984\n",
      "Current iteration=95700, loss=[137324.27937531]\n",
      "||d|| = 5.637589932555837\n",
      "Current iteration=95800, loss=[139914.66339287]\n",
      "||d|| = 1.8310731508785585\n",
      "Current iteration=95900, loss=[136027.94406438]\n",
      "||d|| = 0.49809674980115987\n",
      "Current iteration=96000, loss=[137441.56266682]\n",
      "||d|| = 0.5594748529740996\n",
      "Current iteration=96100, loss=[136607.50865003]\n",
      "||d|| = 0.4518622484091428\n",
      "Current iteration=96200, loss=[137081.91146637]\n",
      "||d|| = 1.1921464942261852\n",
      "Current iteration=96300, loss=[136100.09885187]\n",
      "||d|| = 0.34886575889359733\n",
      "Current iteration=96400, loss=[136077.65373597]\n",
      "||d|| = 1.1819066031911594\n",
      "Current iteration=96500, loss=[141404.37496489]\n",
      "||d|| = 1.7284622508767122\n",
      "Current iteration=96600, loss=[139494.15188337]\n",
      "||d|| = 0.9988616770581636\n",
      "Current iteration=96700, loss=[136318.44355727]\n",
      "||d|| = 2.8825072166409607\n",
      "Current iteration=96800, loss=[136512.00836419]\n",
      "||d|| = 0.9839163364128259\n",
      "Current iteration=96900, loss=[137762.79868872]\n",
      "||d|| = 0.6052142795595812\n",
      "Current iteration=97000, loss=[138183.19248164]\n",
      "||d|| = 0.5111657984546083\n",
      "Current iteration=97100, loss=[136752.80255875]\n",
      "||d|| = 1.3728021837139572\n",
      "Current iteration=97200, loss=[135463.49929572]\n",
      "||d|| = 0.390458898022712\n",
      "Current iteration=97300, loss=[135832.47208848]\n",
      "||d|| = 0.40662357845744584\n",
      "Current iteration=97400, loss=[136276.79286005]\n",
      "||d|| = 0.9248428040760083\n",
      "Current iteration=97500, loss=[135746.40921171]\n",
      "||d|| = 0.41724277052652664\n",
      "Current iteration=97600, loss=[136230.73283544]\n",
      "||d|| = 1.102091796233142\n",
      "Current iteration=97700, loss=[135934.25235885]\n",
      "||d|| = 0.06837299160383595\n",
      "Current iteration=97800, loss=[136191.66184951]\n",
      "||d|| = 10.978974246583114\n",
      "Current iteration=97900, loss=[137616.94218918]\n",
      "||d|| = 0.5325885470161582\n",
      "Current iteration=98000, loss=[135525.10788946]\n",
      "||d|| = 0.8360467771890168\n",
      "Current iteration=98100, loss=[135272.90307599]\n",
      "||d|| = 0.31580028128980536\n",
      "Current iteration=98200, loss=[136134.40568157]\n",
      "||d|| = 1.6195724834595047\n",
      "Current iteration=98300, loss=[137450.23424815]\n",
      "||d|| = 0.7376984821041233\n",
      "Current iteration=98400, loss=[138781.9547896]\n",
      "||d|| = 0.1295744692646685\n",
      "Current iteration=98500, loss=[136573.4053543]\n",
      "||d|| = 0.13471029046393262\n",
      "Current iteration=98600, loss=[140943.14094925]\n",
      "||d|| = 2.613680407549485\n",
      "Current iteration=98700, loss=[136512.97531205]\n",
      "||d|| = 1.0453742982522054\n",
      "Current iteration=98800, loss=[136957.3236311]\n",
      "||d|| = 0.2954618339737672\n",
      "Current iteration=98900, loss=[135997.63427794]\n",
      "||d|| = 0.1729234243944602\n",
      "Current iteration=99000, loss=[137407.733458]\n",
      "||d|| = 0.7299091858701512\n",
      "Current iteration=99100, loss=[135293.47889771]\n",
      "||d|| = 1.0842824544210283\n",
      "Current iteration=99200, loss=[135327.44714217]\n",
      "||d|| = 0.5526664411429096\n",
      "Current iteration=99300, loss=[135322.49052581]\n",
      "||d|| = 6.284650932613694\n",
      "Current iteration=99400, loss=[136380.78790787]\n",
      "||d|| = 1.1713439096176994\n",
      "Current iteration=99500, loss=[137049.09820429]\n",
      "||d|| = 0.9215059846555428\n",
      "Current iteration=99600, loss=[136358.67691208]\n",
      "||d|| = 0.30611853884594864\n",
      "Current iteration=99700, loss=[135947.79379875]\n",
      "||d|| = 0.5730456404417054\n",
      "Current iteration=99800, loss=[136453.17732375]\n",
      "||d|| = 1.7460546911303811\n",
      "Current iteration=99900, loss=[136686.55463375]\n",
      "||d|| = 0.44937032966833224\n",
      "loss=[138897.157523]\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros((tx.shape[1], 1))\n",
    "\n",
    "w, tr_loss = reg_logistic_regression(y, tx, initial_w, 0, 100000, 0.01, method='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result with gamma = 0.001 and 100k iter ||d|| = 0.8317845119149855 loss = 137795.11103903, test set accuracy = 0.67216\n",
    "\n",
    "Result with gamma = 0.01 and 100k iter ||d|| = 0.44937032966833224 loss = [138897.157523], test set accuracy = 0.67562\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub, x_sub_raw, ids_sub = load_csv_data('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sub = x_sub_raw[:, kept_columns]\n",
    "tx_sub = np.c_[np.ones((y_sub.shape[0], 1)), x_sub]\n",
    "y_sub = predict_labels(w, tx_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids_sub, y_sub, 'submissions/10-24.00-15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67562"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_labels(w, tx_test)\n",
    "\n",
    "(y_pred == y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=[173313.04513999]\n",
      "||d|| = 1.26305514443864\n",
      "Current iteration=1000, loss=[168283.06486387]\n",
      "||d|| = 1.819023295795367\n",
      "Current iteration=2000, loss=[166816.44837511]\n",
      "||d|| = 1.0077769045239235\n",
      "Current iteration=3000, loss=[166393.08782902]\n",
      "||d|| = 0.8318294301989898\n",
      "Current iteration=4000, loss=[166597.5718525]\n",
      "||d|| = 2.6272222280554387\n",
      "Current iteration=5000, loss=[166996.0668856]\n",
      "||d|| = 0.8493192680566024\n",
      "Current iteration=6000, loss=[166730.77618249]\n",
      "||d|| = 1.0512566439418087\n",
      "Current iteration=7000, loss=[166921.00926433]\n",
      "||d|| = 3.5558377129950416\n",
      "Current iteration=8000, loss=[166223.62885936]\n",
      "||d|| = 0.6963285060093969\n",
      "Current iteration=9000, loss=[167875.55098277]\n",
      "||d|| = 0.9897859278051709\n",
      "loss=[167745.57591656]\n",
      "lambda=1e-05, Training loss=167800.920, Testing loss=33595.736\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[173346.53609555]\n",
      "||d|| = 0.8728545565961453\n",
      "Current iteration=1000, loss=[168460.05859765]\n",
      "||d|| = 1.3735031108323827\n",
      "Current iteration=2000, loss=[167069.18261408]\n",
      "||d|| = 0.9031784225640527\n",
      "Current iteration=3000, loss=[166427.5666778]\n",
      "||d|| = 3.313056207041964\n",
      "Current iteration=4000, loss=[167170.58652437]\n",
      "||d|| = 0.8834238984740492\n",
      "Current iteration=5000, loss=[167043.85770693]\n",
      "||d|| = 1.2473836233963607\n",
      "Current iteration=6000, loss=[166729.30488526]\n",
      "||d|| = 1.2159318094135076\n",
      "Current iteration=7000, loss=[166632.11606819]\n",
      "||d|| = 0.8832334599975862\n",
      "Current iteration=8000, loss=[166763.64512231]\n",
      "||d|| = 4.1445262831747955\n",
      "Current iteration=9000, loss=[166562.0793495]\n",
      "||d|| = 1.1628000030728962\n",
      "loss=[166020.82586707]\n",
      "lambda=2.2758459260747865e-05, Training loss=166094.293, Testing loss=33251.834\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[173422.75635032]\n",
      "||d|| = 1.2541671263393699\n",
      "Current iteration=1000, loss=[168267.75156578]\n",
      "||d|| = 1.098835951073333\n",
      "Current iteration=2000, loss=[167396.42561941]\n",
      "||d|| = 0.9411108872373528\n",
      "Current iteration=3000, loss=[167039.85050206]\n",
      "||d|| = 2.1436378435095915\n",
      "Current iteration=4000, loss=[166872.30728394]\n",
      "||d|| = 1.9646701997822797\n",
      "Current iteration=5000, loss=[166646.85076211]\n",
      "||d|| = 1.3962040049126478\n",
      "Current iteration=6000, loss=[166654.94139525]\n",
      "||d|| = 1.6076990084711322\n",
      "Current iteration=7000, loss=[167043.47068016]\n",
      "||d|| = 1.128884724565772\n",
      "Current iteration=8000, loss=[165904.80905641]\n",
      "||d|| = 0.7805806719796041\n",
      "Current iteration=9000, loss=[166738.0094186]\n",
      "||d|| = 0.699603365068777\n",
      "loss=[167330.70533768]\n",
      "lambda=5.1794746792312125e-05, Training loss=167494.327, Testing loss=33535.242\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[173596.22190662]\n",
      "||d|| = 4.468479740656699\n",
      "Current iteration=1000, loss=[168780.10935006]\n",
      "||d|| = 1.0590788365502513\n",
      "Current iteration=2000, loss=[167488.76989055]\n",
      "||d|| = 0.8134251827799253\n",
      "Current iteration=3000, loss=[168279.21282592]\n",
      "||d|| = 2.7287072606298275\n",
      "Current iteration=4000, loss=[166998.47209364]\n",
      "||d|| = 4.160577533201783\n",
      "Current iteration=5000, loss=[166557.48707305]\n",
      "||d|| = 1.7463836256739027\n",
      "Current iteration=6000, loss=[167392.6339087]\n",
      "||d|| = 1.0156078423838548\n",
      "Current iteration=7000, loss=[167028.47444461]\n",
      "||d|| = 0.9517221485155577\n",
      "Current iteration=8000, loss=[167564.84988391]\n",
      "||d|| = 1.1450875966127358\n",
      "Current iteration=9000, loss=[167305.20664103]\n",
      "||d|| = 4.946945694418915\n",
      "loss=[166116.06750867]\n",
      "lambda=0.00011787686347935866, Training loss=166422.279, Testing loss=33322.213\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[173991.00278625]\n",
      "||d|| = 5.541875001276259\n",
      "Current iteration=1000, loss=[169008.12180402]\n",
      "||d|| = 1.1894661570349476\n",
      "Current iteration=2000, loss=[167900.61610083]\n",
      "||d|| = 0.9691297314027508\n",
      "Current iteration=3000, loss=[167722.1255699]\n",
      "||d|| = 3.941106161573914\n",
      "Current iteration=4000, loss=[168020.48954807]\n",
      "||d|| = 3.9783988896688998\n",
      "Current iteration=5000, loss=[168267.76251402]\n",
      "||d|| = 3.8984447531600726\n",
      "Current iteration=6000, loss=[166833.91175431]\n",
      "||d|| = 1.551085912807372\n",
      "Current iteration=7000, loss=[167967.10863758]\n",
      "||d|| = 4.230625059296272\n",
      "Current iteration=8000, loss=[168532.85373105]\n",
      "||d|| = 1.2087664063246752\n",
      "Current iteration=9000, loss=[167965.28337612]\n",
      "||d|| = 4.1658471614579975\n",
      "loss=[167316.34776422]\n",
      "lambda=0.0002682695795279727, Training loss=168049.173, Testing loss=33650.404\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[174889.46324284]\n",
      "||d|| = 1.3075116123363506\n",
      "Current iteration=1000, loss=[170178.57839484]\n",
      "||d|| = 1.0659202815722766\n",
      "Current iteration=2000, loss=[168277.63389409]\n",
      "||d|| = 4.0665948861999865\n",
      "Current iteration=3000, loss=[168142.08464237]\n",
      "||d|| = 0.8439289285317253\n",
      "Current iteration=4000, loss=[168179.26136932]\n",
      "||d|| = 0.6996768719667973\n",
      "Current iteration=5000, loss=[168023.42632725]\n",
      "||d|| = 0.742234542551109\n",
      "Current iteration=6000, loss=[168224.01697293]\n",
      "||d|| = 4.0098913250389865\n",
      "Current iteration=7000, loss=[168792.20399253]\n",
      "||d|| = 1.8220175592654464\n",
      "Current iteration=8000, loss=[168086.55194763]\n",
      "||d|| = 0.8435099568052427\n",
      "Current iteration=9000, loss=[168471.13327189]\n",
      "||d|| = 1.4574324534488317\n",
      "loss=[166596.63555184]\n",
      "lambda=0.0006105402296585327, Training loss=168216.929, Testing loss=33681.944\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[176934.22081272]\n",
      "||d|| = 1.0745192705562565\n",
      "Current iteration=1000, loss=[172029.98112241]\n",
      "||d|| = 2.305150031920144\n",
      "Current iteration=2000, loss=[171198.02330418]\n",
      "||d|| = 0.8313862483875408\n",
      "Current iteration=3000, loss=[170990.42928095]\n",
      "||d|| = 3.5123794213133843\n",
      "Current iteration=4000, loss=[171097.62788377]\n",
      "||d|| = 4.254099035527979\n",
      "Current iteration=5000, loss=[170594.07661055]\n",
      "||d|| = 1.7702771437202347\n",
      "Current iteration=6000, loss=[169714.25080376]\n",
      "||d|| = 1.349970127036815\n",
      "Current iteration=7000, loss=[170875.92250961]\n",
      "||d|| = 1.3530092364151882\n",
      "Current iteration=8000, loss=[171135.22269014]\n",
      "||d|| = 1.4027793649586415\n",
      "Current iteration=9000, loss=[171030.73494525]\n",
      "||d|| = 1.2807313141663457\n",
      "loss=[166835.02683782]\n",
      "lambda=0.0013894954943731374, Training loss=170502.150, Testing loss=34142.278\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[181587.77399793]\n",
      "||d|| = 1.1391853132546674\n",
      "Current iteration=1000, loss=[176157.46591759]\n",
      "||d|| = 3.0654332422329773\n",
      "Current iteration=2000, loss=[175163.43294165]\n",
      "||d|| = 3.4500489559902254\n",
      "Current iteration=3000, loss=[174506.44090795]\n",
      "||d|| = 1.0919129465111044\n",
      "Current iteration=4000, loss=[174459.94528618]\n",
      "||d|| = 2.8397301869174814\n",
      "Current iteration=5000, loss=[174700.39568214]\n",
      "||d|| = 1.0727366525916247\n",
      "Current iteration=6000, loss=[175387.19167337]\n",
      "||d|| = 0.8862156826399785\n",
      "Current iteration=7000, loss=[174305.50592982]\n",
      "||d|| = 0.7500416736686961\n",
      "Current iteration=8000, loss=[174975.57134729]\n",
      "||d|| = 0.9636122687013603\n",
      "Current iteration=9000, loss=[175494.54124079]\n",
      "||d|| = 4.164535961315001\n",
      "loss=[166861.22405087]\n",
      "lambda=0.0031622776601683794, Training loss=175163.701, Testing loss=35077.134\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[192178.54405627]\n",
      "||d|| = 1.7102584616375034\n",
      "Current iteration=1000, loss=[187070.1673447]\n",
      "||d|| = 4.277434461109334\n",
      "Current iteration=2000, loss=[185735.84652143]\n",
      "||d|| = 2.105960238469983\n",
      "Current iteration=3000, loss=[186333.77962923]\n",
      "||d|| = 0.8521400223131395\n",
      "Current iteration=4000, loss=[186364.86821188]\n",
      "||d|| = 0.7505026107960762\n",
      "Current iteration=5000, loss=[185443.0298151]\n",
      "||d|| = 0.9182593575537941\n",
      "Current iteration=6000, loss=[186163.0544687]\n",
      "||d|| = 1.3381738358274844\n",
      "Current iteration=7000, loss=[186315.58091869]\n",
      "||d|| = 1.1049132757844498\n",
      "Current iteration=8000, loss=[186766.04918078]\n",
      "||d|| = 4.232676835723373\n",
      "Current iteration=9000, loss=[185907.48724948]\n",
      "||d|| = 1.0883004101988492\n",
      "loss=[167373.2501753]\n",
      "lambda=0.0071968567300115215, Training loss=186262.556, Testing loss=37308.334\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[216281.50494753]\n",
      "||d|| = 0.8655381224604687\n",
      "Current iteration=1000, loss=[210987.7723704]\n",
      "||d|| = 1.7341521704736163\n",
      "Current iteration=2000, loss=[209422.03768237]\n",
      "||d|| = 4.012953759679057\n",
      "Current iteration=3000, loss=[209018.02187707]\n",
      "||d|| = 1.268328375018982\n",
      "Current iteration=4000, loss=[210236.91354088]\n",
      "||d|| = 0.9977386176987163\n",
      "Current iteration=5000, loss=[210130.80136157]\n",
      "||d|| = 1.3866830164181536\n",
      "Current iteration=6000, loss=[209694.84829753]\n",
      "||d|| = 2.3395539912021115\n",
      "Current iteration=7000, loss=[209997.40788817]\n",
      "||d|| = 1.5542206073372797\n",
      "Current iteration=8000, loss=[210279.81012211]\n",
      "||d|| = 4.112407303439851\n",
      "Current iteration=9000, loss=[209672.1515306]\n",
      "||d|| = 2.897254745658401\n",
      "loss=[167092.25010617]\n",
      "lambda=0.016378937069540647, Training loss=210118.435, Testing loss=42085.252\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[271136.13029826]\n",
      "||d|| = 0.9483496339446815\n",
      "Current iteration=1000, loss=[266030.14530878]\n",
      "||d|| = 1.6742374455436124\n",
      "Current iteration=2000, loss=[264931.15091336]\n",
      "||d|| = 1.3703575813144777\n",
      "Current iteration=3000, loss=[264152.08210145]\n",
      "||d|| = 1.3610131639601137\n",
      "Current iteration=4000, loss=[264594.73835943]\n",
      "||d|| = 0.7077120484856743\n",
      "Current iteration=5000, loss=[264639.89832428]\n",
      "||d|| = 4.129031033617864\n",
      "Current iteration=6000, loss=[264151.95373945]\n",
      "||d|| = 0.980751695536922\n",
      "Current iteration=7000, loss=[264092.82168845]\n",
      "||d|| = 1.019824362807536\n",
      "Current iteration=8000, loss=[263660.93478552]\n",
      "||d|| = 0.9567222845770662\n",
      "Current iteration=9000, loss=[264191.04948429]\n",
      "||d|| = 0.8061676815293978\n",
      "loss=[166740.6478794]\n",
      "lambda=0.037275937203149416, Training loss=264598.153, Testing loss=53011.813\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[395976.80592906]\n",
      "||d|| = 1.580624601198548\n",
      "Current iteration=1000, loss=[390918.33102625]\n",
      "||d|| = 0.8446051551269214\n",
      "Current iteration=2000, loss=[389550.75677266]\n",
      "||d|| = 0.9011377359181046\n",
      "Current iteration=3000, loss=[389782.8309837]\n",
      "||d|| = 1.573654846739687\n",
      "Current iteration=4000, loss=[389673.06972948]\n",
      "||d|| = 1.2950574839347255\n",
      "Current iteration=5000, loss=[389427.47473564]\n",
      "||d|| = 0.7197093690957935\n",
      "Current iteration=6000, loss=[389115.69017215]\n",
      "||d|| = 1.7896822431304622\n",
      "Current iteration=7000, loss=[389565.2735106]\n",
      "||d|| = 0.8795486398023088\n",
      "Current iteration=8000, loss=[389173.58500651]\n",
      "||d|| = 1.1157955965355775\n",
      "Current iteration=9000, loss=[389596.68913728]\n",
      "||d|| = 0.6860517625315583\n",
      "loss=[167655.4392395]\n",
      "lambda=0.08483428982440726, Training loss=390326.494, Testing loss=78232.707\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[680094.94897185]\n",
      "||d|| = 2.6627067285904022\n",
      "Current iteration=1000, loss=[675528.38496339]\n",
      "||d|| = 1.0699948082075703\n",
      "Current iteration=2000, loss=[674698.49230596]\n",
      "||d|| = 0.8406129809638427\n",
      "Current iteration=3000, loss=[674218.86313815]\n",
      "||d|| = 0.9512040026456446\n",
      "Current iteration=4000, loss=[673493.12037795]\n",
      "||d|| = 1.4183071013213284\n",
      "Current iteration=5000, loss=[673492.91759067]\n",
      "||d|| = 4.664564981799415\n",
      "Current iteration=6000, loss=[673805.36304486]\n",
      "||d|| = 0.9373217822052708\n",
      "Current iteration=7000, loss=[673172.77236397]\n",
      "||d|| = 1.201460330377661\n",
      "Current iteration=8000, loss=[674021.52316153]\n",
      "||d|| = 0.7571900101412813\n",
      "Current iteration=9000, loss=[673671.19188854]\n",
      "||d|| = 4.093729855166607\n",
      "loss=[166800.53766796]\n",
      "lambda=0.19306977288832497, Training loss=673605.551, Testing loss=135038.335\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[1326704.06733972]\n",
      "||d|| = 1.2243464976918232\n",
      "Current iteration=1000, loss=[1322132.46406816]\n",
      "||d|| = 0.7903695368716083\n",
      "Current iteration=2000, loss=[1321548.7142104]\n",
      "||d|| = 1.460139159748873\n",
      "Current iteration=3000, loss=[1320643.51224802]\n",
      "||d|| = 1.6942236135068813\n",
      "Current iteration=4000, loss=[1320541.03889993]\n",
      "||d|| = 3.370557896512458\n",
      "Current iteration=5000, loss=[1320556.11104971]\n",
      "||d|| = 1.1510650268129288\n",
      "Current iteration=6000, loss=[1320638.96012478]\n",
      "||d|| = 2.364199786482454\n",
      "Current iteration=7000, loss=[1320433.7322297]\n",
      "||d|| = 1.1698112980119728\n",
      "Current iteration=8000, loss=[1320952.78759399]\n",
      "||d|| = 4.847264751758059\n",
      "Current iteration=9000, loss=[1320788.93610306]\n",
      "||d|| = 1.4576776599327703\n",
      "loss=[167022.15985325]\n",
      "lambda=0.4393970560760795, Training loss=1320439.639, Testing loss=264747.998\n",
      "Training accuracy=0.655\n",
      "Current iteration=0, loss=[2798286.79514004]\n",
      "||d|| = 0.8516641039245504\n",
      "Current iteration=1000, loss=[2794415.64664812]\n",
      "||d|| = 0.9344799994871188\n",
      "Current iteration=2000, loss=[2793077.83867476]\n",
      "||d|| = 1.466985252332965\n",
      "Current iteration=3000, loss=[2792881.49124866]\n",
      "||d|| = 0.9731223836877806\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-5, 0, 15)\n",
    "initial_w = np.zeros((tx.shape[1], 1))\n",
    "\n",
    "ws = []\n",
    "tr_losses = []\n",
    "te_losses = []\n",
    "\n",
    "for ind, lambda_ in enumerate(lambdas):\n",
    "    w, tr_loss = reg_logistic_regression(y, tx, initial_w, lambda_, 10000, 0.001, method='newton')\n",
    "    ws.append(w)\n",
    "    te_loss = compute_loss(y_test, tx_test, w, lambda_=lambda_)\n",
    "    tr_losses.append(tr_loss[0])\n",
    "    te_losses.append(te_loss[0])\n",
    "\n",
    "    y_pred = predict_labels(w, tx_test)\n",
    "    training_accuracy = (y_pred == y_test).sum() / y_test.shape[0]\n",
    "\n",
    "    print(\"lambda={lambda_}, Training loss={tr:.3f}, Testing loss={te:.3f}\".format(\n",
    "        lambda_=lambda_, tr=tr_losses[ind], te=te_losses[ind]))\n",
    "    print(\"Training accuracy={acc:.3f}\".format(acc=training_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
