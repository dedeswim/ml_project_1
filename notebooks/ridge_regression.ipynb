{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from src.helpers import load_csv_data, standardize, flatten_jet_features, predict_labels, create_csv_submission, get_jet_indexes, jet_indexes\n",
    "from src.linear.implementations import ridge_regression\n",
    "from src.split import split_data\n",
    "from src.polynomials import build_poly_matrix_vandermonde\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "y, x_raw, ids = load_csv_data('../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, mean_x, std_x = standardize(x_raw)\n",
    "tx = np.c_[np.ones((y.shape[0], 1)), x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.8\n",
    "tx_train, y_train, tx_test, y_test = split_data(tx, y, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, w = ridge_regression(y_train, tx_train, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_labels(w, tx_test, mode='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69216"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred == y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression with flattened jet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = flatten_jet_features(x_raw)\n",
    "x, mean_x, std_x = standardize(x)\n",
    "tx = np.c_[np.ones((y.shape[0], 1)), x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_train, y_train, tx_test, y_test = split_data(tx, y, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, w = ridge_regression(y_train, tx_train, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_labels(w, tx_test, mode='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70966"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred == y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression with flattened jet features and polynomial degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = flatten_jet_features(x_raw)\n",
    "x, mean_x, std_x = standardize(x)\n",
    "tx_poly = build_poly_matrix_vandermonde(x, 12)\n",
    "tx = np.c_[np.ones((y.shape[0], 1)), tx_poly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_train, y_train, tx_test, y_test = split_data(tx, y, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, w = ridge_regression(y_train, tx_train, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_labels(w, tx_test, mode='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79294"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred == y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result with lambda = 0.0001, degree = 12 => 0.79294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub, x_sub_raw, ids_sub = load_csv_data('../data/test.csv')\n",
    "y_pred = predict_labels(w, tx_test, mode='linear')\n",
    "create_csv_submission(ids, y_pred, '../submissions/10-24.22-32.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression with different sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 7\n",
    "ratio = 0.8\n",
    "lambda_ = 0.0001\n",
    "\n",
    "x_train, y_train, x_test, y_test = split_data(x_raw, y, ratio)\n",
    "\n",
    "train_jet_indexes= get_jet_indexes(x_train)\n",
    "test_jet_indexes = get_jet_indexes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = []\n",
    "accuracies = []\n",
    "\n",
    "y_pred = np.zeros((x_test.shape[0], 1))\n",
    "\n",
    "for i in train_jet_indexes:\n",
    "    \n",
    "    tx_train_raw = x_train[train_jet_indexes[i]]\n",
    "    tx_test_raw = x_test[test_jet_indexes[i]]\n",
    "    \n",
    "    tx_train_std = standardize(tx_train_raw)[0]\n",
    "    tx_test_std = standardize(tx_test_raw)[0]\n",
    "    \n",
    "    tx_train_rem = np.delete(tx_train_std, jet_indexes[i], axis=1)\n",
    "    tx_test_rem = np.delete(tx_test_std, jet_indexes[i], axis=1)\n",
    "    \n",
    "    tx_train = build_poly_matrix_vandermonde(tx_train_rem, degree)\n",
    "    tx_test = build_poly_matrix_vandermonde(tx_test_rem, degree)\n",
    "    \n",
    "    loss, w = ridge_regression(y_train[train_jet_indexes[i]], tx_train, lambda_)\n",
    "    \n",
    "    y_pred[test_jet_indexes[i]] = predict_labels(w, tx_test, mode='linear')\n",
    "    ws.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_accuracy = (y_pred == y_test).sum() / (y_test.shape[0])\n",
    "tot_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With degree 12, lambda = 0.001 => test accuracy = 0.710"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub, x_sub_raw, ids_sub = load_csv_data('../data/test.csv')\n",
    "tx_sub_split, y_sub_split, ids_split = jet_split(x_sub_raw, y_sub, ids_sub, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_split_pred = [predict_labels(ws[i], x, mode='linear') for i, x in enumerate(tx_sub_split)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_split_cat = np.concatenate(y_split_pred)\n",
    "ids_split_cat = np.concatenate(ids_split)\n",
    "create_csv_submission(ids_split_cat, y_split_cat, '../submissions/10-24.21-37.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, degree, mean=True):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # Get k'th subgroup in test, others in train\n",
    "    \n",
    "    losses_tr, losses_te, ws = [], [], []\n",
    "    \n",
    "    for k_ in range(k):\n",
    "        \n",
    "        test_indices = k_indices[k_]\n",
    "        train_indices = np.setdiff1d(k_indices.flatten(), test_indices)\n",
    "\n",
    "        y_train = y[train_indices]\n",
    "        x_train = x[train_indices]\n",
    "        y_test = y[test_indices]\n",
    "        x_test = x[test_indices]\n",
    "\n",
    "        # Form data with polynomial degree\n",
    "        x_train_poly = build_poly(x_train, degree)\n",
    "        x_test_poly = build_poly(x_test, degree)\n",
    "\n",
    "        # Ridge regression\n",
    "        loss_tr, w_ridge = ridge_regression(y_train, x_train_poly, lambda_)\n",
    "\n",
    "        # Calculate the loss for test data\n",
    "        loss_te = compute_mse(y_test, x_test_poly, w_ridge)\n",
    "        \n",
    "        losses_tr.append(np.math.sqrt(2 * loss_tr))\n",
    "        losses_te.append(np.math.sqrt(2 * loss_te))\n",
    "        ws.append(w_ridge)\n",
    "    \n",
    "        \n",
    "        \n",
    "    return np.mean(losses_tr), np.mean(losses_te)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
